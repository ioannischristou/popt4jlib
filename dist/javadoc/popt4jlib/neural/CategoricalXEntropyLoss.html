<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_144) on Sun Sep 20 14:47:32 EEST 2020 -->
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>CategoricalXEntropyLoss</title>
<meta name="date" content="2020-09-20">
<link rel="stylesheet" type="text/css" href="../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="CategoricalXEntropyLoss";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":10,"i2":10,"i3":10,"i4":10,"i5":10,"i6":10,"i7":10,"i8":10,"i9":10};
var tabs = {65535:["t0","All Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="class-use/CategoricalXEntropyLoss.html">Use</a></li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../index-files/index-1.html">Index</a></li>
<li><a href="../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../popt4jlib/neural/BaseNNNode.html" title="class in popt4jlib.neural"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../popt4jlib/neural/CategoricalXEntropyLossW.html" title="class in popt4jlib.neural"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../index.html?popt4jlib/neural/CategoricalXEntropyLoss.html" target="_top">Frames</a></li>
<li><a href="CategoricalXEntropyLoss.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#fields.inherited.from.class.popt4jlib.neural.BaseNNNode">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">popt4jlib.neural</div>
<h2 title="Class CategoricalXEntropyLoss" class="title">Class CategoricalXEntropyLoss</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li><a href="../../popt4jlib/neural/BaseNNNode.html" title="class in popt4jlib.neural">popt4jlib.neural.BaseNNNode</a></li>
<li>
<ul class="inheritance">
<li>popt4jlib.neural.CategoricalXEntropyLoss</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../popt4jlib/neural/NNNodeIntf.html" title="interface in popt4jlib.neural">NNNodeIntf</a>, <a href="../../popt4jlib/neural/OutputNNNodeIntf.html" title="interface in popt4jlib.neural">OutputNNNodeIntf</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="typeNameLabel">CategoricalXEntropyLoss</span>
extends <a href="../../popt4jlib/neural/BaseNNNode.html" title="class in popt4jlib.neural">BaseNNNode</a>
implements <a href="../../popt4jlib/neural/OutputNNNodeIntf.html" title="interface in popt4jlib.neural">OutputNNNodeIntf</a></pre>
<div class="block">class implements the Categorical Cross-Entropy loss function, that can only
 be used as the output layer node of multi-class classification problems, 
 where the previous layer has 1 node for each class and these last hidden 
 layer nodes output values in [0,1] (for example, Sigmoid or TanH01).
 Notice that the standard <CODE>FFNN.eval[B]()</CODE> methods that do not 
 require knowledge of the true label are implemented with the same logic as 
 that of the <CODE>InputSignalMaxPosSelector</CODE> class.
 <p>Notes:
 <ul>
 <li>2020-09-18: signal inputs to this node during training are transformed 
 according to the soft-max function to represent probabilities.
 <li>2020-09-20: fixed a bug when computing partial derivatives of this 
 output node, in the methods <CODE>evalPartialDerivativeB()</CODE>.
 </ul>
 <p>Title: popt4jlib</p>
 <p>Description: A Parallel Meta-Heuristic Optimization Library in Java</p>
 <p>Copyright: Copyright (c) 2011-2020</p>
 <p>Company: </p></div>
<dl>
<dt><span class="simpleTagLabel">Version:</span></dt>
<dd>1.0</dd>
<dt><span class="simpleTagLabel">Author:</span></dt>
<dd>Ioannis T. Christou</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../serialized-form.html#popt4jlib.neural.CategoricalXEntropyLoss">Serialized Form</a></dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<ul class="blockList">
<li class="blockList"><a name="fields.inherited.from.class.popt4jlib.neural.BaseNNNode">
<!--   -->
</a>
<h3>Fields inherited from class&nbsp;popt4jlib.neural.<a href="../../popt4jlib/neural/BaseNNNode.html" title="class in popt4jlib.neural">BaseNNNode</a></h3>
<code><a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_antecedentWeights">_antecedentWeights</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_biasInd">_biasInd</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_endWeightInd">_endWeightInd</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_ffnn">_ffnn</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_startWeightInd">_startWeightInd</a></code></li>
</ul>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/CategoricalXEntropyLoss.html#CategoricalXEntropyLoss--">CategoricalXEntropyLoss</a></span>()</code>
<div class="block">(sole) public constructor is a no-op.</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/CategoricalXEntropyLoss.html#eval-double:A-double:A-">eval</a></span>(double[]&nbsp;inputSignals,
    double[]&nbsp;weights)</code>
<div class="block">called during network evaluation (run-time or "predict-time"): computes and
 returns the index in inputSignals argument that has the largest value.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/CategoricalXEntropyLoss.html#eval-double:A-double:A-int-">eval</a></span>(double[]&nbsp;inputSignals,
    double[]&nbsp;weights,
    int&nbsp;offset)</code>
<div class="block">same as <CODE>eval(s,w)</CODE> method, but the 2nd argument is now assumed
 to hold all the network weights.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/CategoricalXEntropyLoss.html#eval-double:A-double:A-int-double-">eval</a></span>(double[]&nbsp;inputSignals,
    double[]&nbsp;weights,
    int&nbsp;offset,
    double&nbsp;true_label)</code>
<div class="block">called during training when the node is used as output node, and returns 
 the cross-entropy of the given input data instance, for the network with 
 the given weights PLUS the true label value.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/CategoricalXEntropyLoss.html#evalB-double:A-double:A-">evalB</a></span>(double[]&nbsp;inputSignals,
     double[]&nbsp;weights)</code>
<div class="block">same as <CODE>eval(s,w)</CODE> method, but the 2nd argument is now assumed
 to hold the bias of the node as well (goes unused).</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/CategoricalXEntropyLoss.html#evalB-double:A-double:A-int-">evalB</a></span>(double[]&nbsp;inputSignals,
     double[]&nbsp;weights,
     int&nbsp;offset)</code>
<div class="block">same as <CODE>evalB(s,w)</CODE> method, but the 2nd argument is now assumed
 to hold as last element the bias term for this node (still goes unused).</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/CategoricalXEntropyLoss.html#evalB-double:A-double:A-int-double-">evalB</a></span>(double[]&nbsp;inputSignals,
     double[]&nbsp;weights,
     int&nbsp;offset,
     double&nbsp;true_label)</code>
<div class="block">called when the node is used as output node during training is exactly the 
 same as <CODE>eval(inputSignals,weights,offset,true_label)</CODE>.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/CategoricalXEntropyLoss.html#evalPartialDerivativeB-double:A-int-double:A-double-">evalPartialDerivativeB</a></span>(double[]&nbsp;weights,
                      int&nbsp;index,
                      double[]&nbsp;inputSignals,
                      double&nbsp;true_lbl)</code>
<div class="block">evaluates the partial derivative of this node (as a function of weights)
 with respect to the weight variable whose weight is given by the value of 
 the weights array in the given index, using the grad vector thread local 
 cache.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/CategoricalXEntropyLoss.html#evalPartialDerivativeB-double:A-int-double:A-double-java.util.HashMap-">evalPartialDerivativeB</a></span>(double[]&nbsp;weights,
                      int&nbsp;index,
                      double[]&nbsp;inputSignals,
                      double&nbsp;true_lbl,
                      java.util.HashMap&nbsp;p)</code>
<div class="block">evaluates the partial derivative of this node (as a function of weights)
 with respect to the weight variable whose weight is given by the value of 
 the weights array in the given index.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/CategoricalXEntropyLoss.html#getNodeName--">getNodeName</a></span>()</code>
<div class="block">get this node's name.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/CategoricalXEntropyLoss.html#isDropout--">isDropout</a></span>()</code>
<div class="block">can never become drop-out node.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.popt4jlib.neural.BaseNNNode">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;popt4jlib.neural.<a href="../../popt4jlib/neural/BaseNNNode.html" title="class in popt4jlib.neural">BaseNNNode</a></h3>
<code><a href="../../popt4jlib/neural/BaseNNNode.html#addPreviousWeightsRange-int-int-">addPreviousWeightsRange</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#getBiasIndex--">getBiasIndex</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#getDirectInputWeightEndIndex--">getDirectInputWeightEndIndex</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#getDirectInputWeightStartIndex--">getDirectInputWeightStartIndex</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#getFFNN4TrainB--">getFFNN4TrainB</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#getGradVectorCache--">getGradVectorCache</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#getHiddenNodeLayer--">getHiddenNodeLayer</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#getLastDerivEvalCache--">getLastDerivEvalCache</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#getLastDerivEvalCache2--">getLastDerivEvalCache2</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#getLastEvalCache--">getLastEvalCache</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#getLastInputsCache--">getLastInputsCache</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#getNodeLayer--">getNodeLayer</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#getPositionInLayer--">getPositionInLayer</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#getTotalNumWeights--">getTotalNumWeights</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#isWeightVariableAntecedent-int-">isWeightVariableAntecedent</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#resetCache--">resetCache</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#resetGradVectorCache--">resetGradVectorCache</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#setDropout-boolean-">setDropout</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#setFFNN4TrainB-popt4jlib.neural.FFNN4TrainB-">setFFNN4TrainB</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#setGradVectorCache-double:A-">setGradVectorCache</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#setGradVectorCache-int-double-">setGradVectorCache</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#setLastDerivEvalCache-double-">setLastDerivEvalCache</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#setLastDerivEvalCache2-double-">setLastDerivEvalCache2</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#setLastEvalCache-double-">setLastEvalCache</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#setLastInputsCache-double:A-">setLastInputsCache</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#setNodeLayer-int-">setNodeLayer</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#setPositionInLayer-int-">setPositionInLayer</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#setTotalNumWeights-int-">setTotalNumWeights</a>, <a href="../../popt4jlib/neural/BaseNNNode.html#setWeightRange-int-int-">setWeightRange</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.popt4jlib.neural.NNNodeIntf">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;popt4jlib.neural.<a href="../../popt4jlib/neural/NNNodeIntf.html" title="interface in popt4jlib.neural">NNNodeIntf</a></h3>
<code><a href="../../popt4jlib/neural/NNNodeIntf.html#addPreviousWeightsRange-int-int-">addPreviousWeightsRange</a>, <a href="../../popt4jlib/neural/NNNodeIntf.html#getDirectInputWeightEndIndex--">getDirectInputWeightEndIndex</a>, <a href="../../popt4jlib/neural/NNNodeIntf.html#getDirectInputWeightStartIndex--">getDirectInputWeightStartIndex</a>, <a href="../../popt4jlib/neural/NNNodeIntf.html#getFFNN4TrainB--">getFFNN4TrainB</a>, <a href="../../popt4jlib/neural/NNNodeIntf.html#getNodeLayer--">getNodeLayer</a>, <a href="../../popt4jlib/neural/NNNodeIntf.html#getPositionInLayer--">getPositionInLayer</a>, <a href="../../popt4jlib/neural/NNNodeIntf.html#getTotalNumWeights--">getTotalNumWeights</a>, <a href="../../popt4jlib/neural/NNNodeIntf.html#isWeightVariableAntecedent-int-">isWeightVariableAntecedent</a>, <a href="../../popt4jlib/neural/NNNodeIntf.html#setDropout-boolean-">setDropout</a>, <a href="../../popt4jlib/neural/NNNodeIntf.html#setFFNN4TrainB-popt4jlib.neural.FFNN4TrainB-">setFFNN4TrainB</a>, <a href="../../popt4jlib/neural/NNNodeIntf.html#setNodeLayer-int-">setNodeLayer</a>, <a href="../../popt4jlib/neural/NNNodeIntf.html#setPositionInLayer-int-">setPositionInLayer</a>, <a href="../../popt4jlib/neural/NNNodeIntf.html#setTotalNumWeights-int-">setTotalNumWeights</a>, <a href="../../popt4jlib/neural/NNNodeIntf.html#setWeightRange-int-int-">setWeightRange</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="CategoricalXEntropyLoss--">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>CategoricalXEntropyLoss</h4>
<pre>public&nbsp;CategoricalXEntropyLoss()</pre>
<div class="block">(sole) public constructor is a no-op.</div>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="eval-double:A-double:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>eval</h4>
<pre>public&nbsp;double&nbsp;eval(double[]&nbsp;inputSignals,
                   double[]&nbsp;weights)</pre>
<div class="block">called during network evaluation (run-time or "predict-time"): computes and
 returns the index in inputSignals argument that has the largest value.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../popt4jlib/neural/NNNodeIntf.html#eval-double:A-double:A-">eval</a></code>&nbsp;in interface&nbsp;<code><a href="../../popt4jlib/neural/NNNodeIntf.html" title="interface in popt4jlib.neural">NNNodeIntf</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>inputSignals</code> - double[]</dd>
<dd><code>weights</code> - double[] unused</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double  // int in {0,1,...inputSignals.length-1}</dd>
</dl>
</li>
</ul>
<a name="eval-double:A-double:A-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>eval</h4>
<pre>public&nbsp;double&nbsp;eval(double[]&nbsp;inputSignals,
                   double[]&nbsp;weights,
                   int&nbsp;offset)</pre>
<div class="block">same as <CODE>eval(s,w)</CODE> method, but the 2nd argument is now assumed
 to hold all the network weights.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../popt4jlib/neural/NNNodeIntf.html#eval-double:A-double:A-int-">eval</a></code>&nbsp;in interface&nbsp;<code><a href="../../popt4jlib/neural/NNNodeIntf.html" title="interface in popt4jlib.neural">NNNodeIntf</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>inputSignals</code> - double[]</dd>
<dd><code>weights</code> - double[] unused</dd>
<dd><code>offset</code> - int unused</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double  // int in {0,1,...inputSignals.length-1}</dd>
</dl>
</li>
</ul>
<a name="evalB-double:A-double:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evalB</h4>
<pre>public&nbsp;double&nbsp;evalB(double[]&nbsp;inputSignals,
                    double[]&nbsp;weights)</pre>
<div class="block">same as <CODE>eval(s,w)</CODE> method, but the 2nd argument is now assumed
 to hold the bias of the node as well (goes unused).</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../popt4jlib/neural/NNNodeIntf.html#evalB-double:A-double:A-">evalB</a></code>&nbsp;in interface&nbsp;<code><a href="../../popt4jlib/neural/NNNodeIntf.html" title="interface in popt4jlib.neural">NNNodeIntf</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>inputSignals</code> - double[]</dd>
<dd><code>weights</code> - double[] unused; bias also has no role here</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double  // int in {0,1,...inputSignals.length-1}</dd>
</dl>
</li>
</ul>
<a name="evalB-double:A-double:A-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evalB</h4>
<pre>public&nbsp;double&nbsp;evalB(double[]&nbsp;inputSignals,
                    double[]&nbsp;weights,
                    int&nbsp;offset)</pre>
<div class="block">same as <CODE>evalB(s,w)</CODE> method, but the 2nd argument is now assumed
 to hold as last element the bias term for this node (still goes unused).</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../popt4jlib/neural/NNNodeIntf.html#evalB-double:A-double:A-int-">evalB</a></code>&nbsp;in interface&nbsp;<code><a href="../../popt4jlib/neural/NNNodeIntf.html" title="interface in popt4jlib.neural">NNNodeIntf</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>inputSignals</code> - double[]</dd>
<dd><code>weights</code> - double[] unused; bias also has no role here</dd>
<dd><code>offset</code> - int unused</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double  // int in {0,1,...inputSignals.length-1}</dd>
</dl>
</li>
</ul>
<a name="eval-double:A-double:A-int-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>eval</h4>
<pre>public&nbsp;double&nbsp;eval(double[]&nbsp;inputSignals,
                   double[]&nbsp;weights,
                   int&nbsp;offset,
                   double&nbsp;true_label)</pre>
<div class="block">called during training when the node is used as output node, and returns 
 the cross-entropy of the given input data instance, for the network with 
 the given weights PLUS the true label value. Input signals are transformed 
 according to the soft-max function first.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../popt4jlib/neural/OutputNNNodeIntf.html#eval-double:A-double:A-int-double-">eval</a></code>&nbsp;in interface&nbsp;<code><a href="../../popt4jlib/neural/OutputNNNodeIntf.html" title="interface in popt4jlib.neural">OutputNNNodeIntf</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>inputSignals</code> - double[]</dd>
<dd><code>weights</code> - double[] unused</dd>
<dd><code>offset</code> - int unused</dd>
<dd><code>true_label</code> - double value in {0,...,inputSignals.length-1}</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double</dd>
</dl>
</li>
</ul>
<a name="evalB-double:A-double:A-int-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evalB</h4>
<pre>public&nbsp;double&nbsp;evalB(double[]&nbsp;inputSignals,
                    double[]&nbsp;weights,
                    int&nbsp;offset,
                    double&nbsp;true_label)</pre>
<div class="block">called when the node is used as output node during training is exactly the 
 same as <CODE>eval(inputSignals,weights,offset,true_label)</CODE>.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../popt4jlib/neural/OutputNNNodeIntf.html#evalB-double:A-double:A-int-double-">evalB</a></code>&nbsp;in interface&nbsp;<code><a href="../../popt4jlib/neural/OutputNNNodeIntf.html" title="interface in popt4jlib.neural">OutputNNNodeIntf</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>inputSignals</code> - double[]</dd>
<dd><code>weights</code> - double[] unused</dd>
<dd><code>offset</code> - int unused</dd>
<dd><code>true_label</code> - double value in {0,...inputSignals.length-1}</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double</dd>
</dl>
</li>
</ul>
<a name="getNodeName--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getNodeName</h4>
<pre>public&nbsp;java.lang.String&nbsp;getNodeName()</pre>
<div class="block">get this node's name.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../popt4jlib/neural/NNNodeIntf.html#getNodeName--">getNodeName</a></code>&nbsp;in interface&nbsp;<code><a href="../../popt4jlib/neural/NNNodeIntf.html" title="interface in popt4jlib.neural">NNNodeIntf</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>String "CategoricalXEntropyLoss"</dd>
</dl>
</li>
</ul>
<a name="evalPartialDerivativeB-double:A-int-double:A-double-java.util.HashMap-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evalPartialDerivativeB</h4>
<pre>public&nbsp;double&nbsp;evalPartialDerivativeB(double[]&nbsp;weights,
                                     int&nbsp;index,
                                     double[]&nbsp;inputSignals,
                                     double&nbsp;true_lbl,
                                     java.util.HashMap&nbsp;p)</pre>
<div class="block">evaluates the partial derivative of this node (as a function of weights)
 with respect to the weight variable whose weight is given by the value of 
 the weights array in the given index. Notice that the computation takes 
 into account that the input signals to this node are first transformed via
 the soft-max transform.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../popt4jlib/neural/NNNodeIntf.html#evalPartialDerivativeB-double:A-int-double:A-double-java.util.HashMap-">evalPartialDerivativeB</a></code>&nbsp;in interface&nbsp;<code><a href="../../popt4jlib/neural/NNNodeIntf.html" title="interface in popt4jlib.neural">NNNodeIntf</a></code></dd>
<dt><span class="overrideSpecifyLabel">Overrides:</span></dt>
<dd><code><a href="../../popt4jlib/neural/BaseNNNode.html#evalPartialDerivativeB-double:A-int-double:A-double-java.util.HashMap-">evalPartialDerivativeB</a></code>&nbsp;in class&nbsp;<code><a href="../../popt4jlib/neural/BaseNNNode.html" title="class in popt4jlib.neural">BaseNNNode</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>weights</code> - double[] all variables (including biases) array</dd>
<dd><code>index</code> - int the index of the partial derivative to take</dd>
<dd><code>inputSignals</code> - double[] the training instance</dd>
<dd><code>true_lbl</code> - double the training label</dd>
<dd><code>p</code> - HashMap includes the train-data matrix and train-labels array.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double</dd>
</dl>
</li>
</ul>
<a name="evalPartialDerivativeB-double:A-int-double:A-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evalPartialDerivativeB</h4>
<pre>public&nbsp;double&nbsp;evalPartialDerivativeB(double[]&nbsp;weights,
                                     int&nbsp;index,
                                     double[]&nbsp;inputSignals,
                                     double&nbsp;true_lbl)</pre>
<div class="block">evaluates the partial derivative of this node (as a function of weights)
 with respect to the weight variable whose weight is given by the value of 
 the weights array in the given index, using the grad vector thread local 
 cache. Notice that the computation takes into account that the input 
 signals to this node are first transformed via the soft-max transform.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../popt4jlib/neural/NNNodeIntf.html#evalPartialDerivativeB-double:A-int-double:A-double-">evalPartialDerivativeB</a></code>&nbsp;in interface&nbsp;<code><a href="../../popt4jlib/neural/NNNodeIntf.html" title="interface in popt4jlib.neural">NNNodeIntf</a></code></dd>
<dt><span class="overrideSpecifyLabel">Overrides:</span></dt>
<dd><code><a href="../../popt4jlib/neural/BaseNNNode.html#evalPartialDerivativeB-double:A-int-double:A-double-">evalPartialDerivativeB</a></code>&nbsp;in class&nbsp;<code><a href="../../popt4jlib/neural/BaseNNNode.html" title="class in popt4jlib.neural">BaseNNNode</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>weights</code> - double[] all variables (including biases) array</dd>
<dd><code>index</code> - int the index of the partial derivative to take</dd>
<dd><code>inputSignals</code> - double[] the training instance</dd>
<dd><code>true_lbl</code> - double the training label</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double</dd>
</dl>
</li>
</ul>
<a name="isDropout--">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>isDropout</h4>
<pre>public&nbsp;boolean&nbsp;isDropout()</pre>
<div class="block">can never become drop-out node.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../popt4jlib/neural/NNNodeIntf.html#isDropout--">isDropout</a></code>&nbsp;in interface&nbsp;<code><a href="../../popt4jlib/neural/NNNodeIntf.html" title="interface in popt4jlib.neural">NNNodeIntf</a></code></dd>
<dt><span class="overrideSpecifyLabel">Overrides:</span></dt>
<dd><code><a href="../../popt4jlib/neural/BaseNNNode.html#isDropout--">isDropout</a></code>&nbsp;in class&nbsp;<code><a href="../../popt4jlib/neural/BaseNNNode.html" title="class in popt4jlib.neural">BaseNNNode</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>false always</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="class-use/CategoricalXEntropyLoss.html">Use</a></li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../index-files/index-1.html">Index</a></li>
<li><a href="../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../popt4jlib/neural/BaseNNNode.html" title="class in popt4jlib.neural"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../popt4jlib/neural/CategoricalXEntropyLossW.html" title="class in popt4jlib.neural"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../index.html?popt4jlib/neural/CategoricalXEntropyLoss.html" target="_top">Frames</a></li>
<li><a href="CategoricalXEntropyLoss.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#fields.inherited.from.class.popt4jlib.neural.BaseNNNode">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
