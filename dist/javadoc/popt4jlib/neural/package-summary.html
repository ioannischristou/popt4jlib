<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_144) on Wed Jan 06 12:54:57 EET 2021 -->
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>popt4jlib.neural</title>
<meta name="date" content="2021-01-06">
<link rel="stylesheet" type="text/css" href="../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="popt4jlib.neural";
        }
    }
    catch(err) {
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../overview-summary.html">Overview</a></li>
<li class="navBarCell1Rev">Package</li>
<li>Class</li>
<li><a href="package-use.html">Use</a></li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../index-files/index-1.html">Index</a></li>
<li><a href="../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../popt4jlib/network/package-summary.html">Prev&nbsp;Package</a></li>
<li><a href="../../popt4jlib/neural/costfunction/package-summary.html">Next&nbsp;Package</a></li>
</ul>
<ul class="navList">
<li><a href="../../index.html?popt4jlib/neural/package-summary.html" target="_top">Frames</a></li>
<li><a href="package-summary.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<div class="header">
<h1 title="Package" class="title">Package&nbsp;popt4jlib.neural</h1>
<div class="docSummary">
<div class="block">Neural Network Related Algorithms Parallel Implementation.</div>
</div>
<p>See:&nbsp;<a href="#package.description">Description</a></p>
</div>
<div class="contentContainer">
<ul class="blockList">
<li class="blockList">
<table class="typeSummary" border="0" cellpadding="3" cellspacing="0" summary="Interface Summary table, listing interfaces, and an explanation">
<caption><span>Interface Summary</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Interface</th>
<th class="colLast" scope="col">Description</th>
</tr>
<tbody>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/NNNodeIntf.html" title="interface in popt4jlib.neural">NNNodeIntf</a></td>
<td class="colLast">
<div class="block">common interface for a Neural Network node at any hidden layer.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="../../popt4jlib/neural/OutputNNNodeIntf.html" title="interface in popt4jlib.neural">OutputNNNodeIntf</a></td>
<td class="colLast">
<div class="block">common interface for a Neural Network node that can be used as hidden or 
 output layer node.</div>
</td>
</tr>
</tbody>
</table>
</li>
<li class="blockList">
<table class="typeSummary" border="0" cellpadding="3" cellspacing="0" summary="Class Summary table, listing classes, and an explanation">
<caption><span>Class Summary</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Class</th>
<th class="colLast" scope="col">Description</th>
</tr>
<tbody>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/Adam4FFNN.html" title="class in popt4jlib.neural">Adam4FFNN</a></td>
<td class="colLast">
<div class="block">same as <CODE>popt4jlib.GradientDescent.stochastic.Adam</CODE> but with the
 added hard-wired knowledge of mini-batch training, so that when computing
 derivatives, it actually maintains the same mini-batch in each derivative
 evaluation.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/BaseNNNode.html" title="class in popt4jlib.neural">BaseNNNode</a></td>
<td class="colLast">
<div class="block">base class for NNNodeIntf that implements common functionalities of
 the FFNN nodes.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="../../popt4jlib/neural/CategoricalXEntropyLoss.html" title="class in popt4jlib.neural">CategoricalXEntropyLoss</a></td>
<td class="colLast">
<div class="block">class implements the Categorical Cross-Entropy loss function, that can only
 be used as the output layer node of multi-class classification problems, 
 where the previous layer has 1 node for each class and these last hidden 
 layer nodes output values in [0,1] (for example, Sigmoid or TanH01).</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/CategoricalXEntropyLossW.html" title="class in popt4jlib.neural">CategoricalXEntropyLossW</a></td>
<td class="colLast">
<div class="block">same as the <CODE>CategoricalXEntropyLoss</CODE> class, but when used as the 
 output node, divides the value of the input of the node corresponding to the 
 true label by the sum of the input signals of all its inputs.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="../../popt4jlib/neural/DGAFFNNRun.html" title="class in popt4jlib.neural">DGAFFNNRun</a></td>
<td class="colLast">
<div class="block">Test-driver program for optimizing feed-forward neural networks via the 
 Distributed Genetic Algorithm meta-heuristic optimizer.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/FasterFFNN4TrainBGrad.html" title="class in popt4jlib.neural">FasterFFNN4TrainBGrad</a></td>
<td class="colLast">
<div class="block">implements the Back-Propagation algorithm for computing the gradient of a 
 feed-forward neural network FFNN4TrainB object, on a given (x,y) training 
 pair.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/FastFFNN4TrainBGrad.html" title="class in popt4jlib.neural">FastFFNN4TrainBGrad</a></td>
<td class="colLast">
<div class="block">FastFFNN4TrainBGrad implements the gradient function of an FFNN4TrainB feed
 forward neural network function but faster than FFNN4TrainBGrad because it
 doesn't compute each partial derivative with separate function calls, but 
 all in the same call per training instance, thus maintaining in the cache the
 computations.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/FFNN.html" title="class in popt4jlib.neural">FFNN</a></td>
<td class="colLast">
<div class="block">FFNN implements a standard feef-forward ANN, with arbitrary inputs, hidden
 layers, and a single output node.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="../../popt4jlib/neural/FFNN4Train.html" title="class in popt4jlib.neural">FFNN4Train</a></td>
<td class="colLast">
<div class="block">FFNN4Train extends FFNN that implements a standard feef-forward ANN, with 
 arbitrary inputs, hidden layers, and a single output node.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/FFNN4Train.FFNNMultiEvalTask.html" title="class in popt4jlib.neural">FFNN4Train.FFNNMultiEvalTask</a></td>
<td class="colLast">
<div class="block">static auxiliary class not part of the public API.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="../../popt4jlib/neural/FFNN4TrainB.html" title="class in popt4jlib.neural">FFNN4TrainB</a></td>
<td class="colLast">
<div class="block">FFNN4TrainB extends FFNN4Train and adds the requirement that all nodes in the
 FFNN have one more trainable variable (encoded as their last weight input
 variable), namely a bias.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="../../popt4jlib/neural/FFNN4TrainB.FFNNMultiEvalTaskB.html" title="class in popt4jlib.neural">FFNN4TrainB.FFNNMultiEvalTaskB</a></td>
<td class="colLast">
<div class="block">static auxiliary class not part of the public API.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/FFNN4TrainBGrad.html" title="class in popt4jlib.neural">FFNN4TrainBGrad</a></td>
<td class="colLast">
<div class="block">FFNN4TrainBGrad implements the gradient function of an FFNN4TrainB feed
 forward neural network function.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="../../popt4jlib/neural/FFNN4TrainEvalPDBTExecInitCmd.html" title="class in popt4jlib.neural">FFNN4TrainEvalPDBTExecInitCmd</a></td>
<td class="colLast">
<div class="block">auxiliary class used to initialize workers participating in a distributed 
 network of machines evaluating the function <CODE>FFNN4Train</CODE>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/GELU.html" title="class in popt4jlib.neural">GELU</a></td>
<td class="colLast">
<div class="block">GELU implements the Gaussian Error Linear Unit function used by Google, but
 described in Hendrycks et al (2016), "Gaussian Error Linear Units (GELUs)".</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="../../popt4jlib/neural/HardThres.html" title="class in popt4jlib.neural">HardThres</a></td>
<td class="colLast">
<div class="block">HardThres implements the hard-threshold function in ANNs can be used both as
 hidden layer node and output node.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/InputSignalMaxPosSelector.html" title="class in popt4jlib.neural">InputSignalMaxPosSelector</a></td>
<td class="colLast">
<div class="block">class implements the arg-max selector function that can be used as output
 node when the output layer should consist of more than one node.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="../../popt4jlib/neural/Linear.html" title="class in popt4jlib.neural">Linear</a></td>
<td class="colLast">
<div class="block">Linear implements the linear activation function, and can be used as hidden
 layer node or as output node.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/MultiClassSSE.html" title="class in popt4jlib.neural">MultiClassSSE</a></td>
<td class="colLast">
<div class="block">class implements the max input signal position selector when acting as an 
 input training instance evaluator.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="../../popt4jlib/neural/OptFFNNRun.html" title="class in popt4jlib.neural">OptFFNNRun</a></td>
<td class="colLast">
<div class="block">Test-driver program for optimizing feed-forward neural networks via ANY of 
 the meta-heuristic optimizers available in this library.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/PDMiniBatchBackPropagation.html" title="class in popt4jlib.neural">PDMiniBatchBackPropagation</a></td>
<td class="colLast">
<div class="block">implements a parallel/distributed version of the mini-batch Back Propagation
 classical algorithm for neural network training (BackProp here means not just
 the automatic differentiation of the feed-forward neural network, but the 
 stochastic gradient descent with fixed step-size as well).</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="../../popt4jlib/neural/Quadratic.html" title="class in popt4jlib.neural">Quadratic</a></td>
<td class="colLast">
<div class="block">Quadratic implements the linear activation function and can be used as hidden
 layer node or as output node.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/ReLU.html" title="class in popt4jlib.neural">ReLU</a></td>
<td class="colLast">
<div class="block">ReLU implements the x_{+} function known in ANN literature as RectiLinear
 Activation Unit.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="../../popt4jlib/neural/SGD4FFNN.html" title="class in popt4jlib.neural">SGD4FFNN</a></td>
<td class="colLast">
<div class="block">same as <CODE>popt4jlib.GradientDescent.stochastic.SGD</CODE> but with the
 added hard-wired knowledge of mini-batch training, so that when computing
 derivatives, it actually maintains the same mini-batch in each derivative
 evaluation.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="../../popt4jlib/neural/Sigmoid.html" title="class in popt4jlib.neural">Sigmoid</a></td>
<td class="colLast">
<div class="block">Sigmoid implements the 1/(1+exp(-ax)) function as activation function of a 
 node.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/SoftPlus.html" title="class in popt4jlib.neural">SoftPlus</a></td>
<td class="colLast">
<div class="block">SoftPlus implements the ln(1+exp(ax))/a function as activation function of a 
 node.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="../../popt4jlib/neural/TanH.html" title="class in popt4jlib.neural">TanH</a></td>
<td class="colLast">
<div class="block">TanH implements the tanh function as activation function of a node.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/TanH01.html" title="class in popt4jlib.neural">TanH01</a></td>
<td class="colLast">
<div class="block">TanH01 implements the tanh function, scaled and shifted so as to produce 
 values in [0,1] as activation function of a node.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="../../popt4jlib/neural/TanHM11.html" title="class in popt4jlib.neural">TanHM11</a></td>
<td class="colLast">
<div class="block">TanHM11 implements a special tanh function as activation function of a node,
 according to the recommendations of Chapter 1 in "Neural Networks: Tricks of
 the Trade", 2nd edition, 2012.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="../../popt4jlib/neural/TrainData.html" title="class in popt4jlib.neural">TrainData</a></td>
<td class="colLast">
<div class="block">Auxiliary class that serves as a place-holder for caching data for training
 neural networks, and making them available via static method calls.</div>
</td>
</tr>
</tbody>
</table>
</li>
</ul>
<a name="package.description">
<!--   -->
</a>
<h2 title="Package popt4jlib.neural Description">Package popt4jlib.neural Description</h2>
<div class="block">Neural Network Related Algorithms Parallel Implementation.

<h2>Package Specification</h2>
This package contains a number of classes that implement classical (and semi-
classical) algorithms for ANN (and DL) optimization problems, with an emphasis
on algorithms that are parallel in nature, and are suited for a multi-core 
shared-memory implementation. 
<ul>
  <li><a href="">hyperlink</a>
</ul>

<h2>Related Documentation</h2>

<ul>
  <li><a href="">hyperlink</a>
</ul>

<!-- Put @see and @since tags here. --></div>
</div>
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../overview-summary.html">Overview</a></li>
<li class="navBarCell1Rev">Package</li>
<li>Class</li>
<li><a href="package-use.html">Use</a></li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../index-files/index-1.html">Index</a></li>
<li><a href="../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../popt4jlib/network/package-summary.html">Prev&nbsp;Package</a></li>
<li><a href="../../popt4jlib/neural/costfunction/package-summary.html">Next&nbsp;Package</a></li>
</ul>
<ul class="navList">
<li><a href="../../index.html?popt4jlib/neural/package-summary.html" target="_top">Frames</a></li>
<li><a href="package-summary.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
