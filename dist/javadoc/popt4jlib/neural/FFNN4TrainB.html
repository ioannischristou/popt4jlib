<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_144) on Fri May 14 19:05:57 EEST 2021 -->
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>FFNN4TrainB</title>
<meta name="date" content="2021-05-14">
<link rel="stylesheet" type="text/css" href="../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="FFNN4TrainB";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":10,"i2":10,"i3":10,"i4":10,"i5":10,"i6":10,"i7":10,"i8":10,"i9":10,"i10":10,"i11":10,"i12":10,"i13":10,"i14":10,"i15":10,"i16":9,"i17":10,"i18":10,"i19":10,"i20":10};
var tabs = {65535:["t0","All Methods"],1:["t1","Static Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="class-use/FFNN4TrainB.html">Use</a></li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../index-files/index-1.html">Index</a></li>
<li><a href="../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../popt4jlib/neural/FFNN4Train.FFNNMultiEvalTask.html" title="class in popt4jlib.neural"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../popt4jlib/neural/FFNN4TrainB.FFNNMultiEvalPartialDerivTaskB.html" title="class in popt4jlib.neural"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../index.html?popt4jlib/neural/FFNN4TrainB.html" target="_top">Frames</a></li>
<li><a href="FFNN4TrainB.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.class.summary">Nested</a>&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">popt4jlib.neural</div>
<h2 title="Class FFNN4TrainB" class="title">Class FFNN4TrainB</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li><a href="../../popt4jlib/neural/FFNN.html" title="class in popt4jlib.neural">popt4jlib.neural.FFNN</a></li>
<li>
<ul class="inheritance">
<li><a href="../../popt4jlib/neural/FFNN4Train.html" title="class in popt4jlib.neural">popt4jlib.neural.FFNN4Train</a></li>
<li>
<ul class="inheritance">
<li>popt4jlib.neural.FFNN4TrainB</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../popt4jlib/FunctionIntf.html" title="interface in popt4jlib">FunctionIntf</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="typeNameLabel">FFNN4TrainB</span>
extends <a href="../../popt4jlib/neural/FFNN4Train.html" title="class in popt4jlib.neural">FFNN4Train</a></pre>
<div class="block">FFNN4TrainB extends FFNN4Train and adds the requirement that all nodes in the
 FFNN have one more trainable variable (encoded as their last weight input
 variable), namely a bias. 
 <p>Title: popt4jlib</p>
 <p>Description: A Parallel Meta-Heuristic Optimization Library in Java</p>
 <p>Copyright: Copyright (c) 2011-2020</p>
 <p>Company: </p></div>
<dl>
<dt><span class="simpleTagLabel">Version:</span></dt>
<dd>1.0</dd>
<dt><span class="simpleTagLabel">Author:</span></dt>
<dd>Ioannis T. Christou</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../serialized-form.html#popt4jlib.neural.FFNN4TrainB">Serialized Form</a></dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested.class.summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>(package private) class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.FFNNMultiEvalPartialDerivTaskB.html" title="class in popt4jlib.neural">FFNN4TrainB.FFNNMultiEvalPartialDerivTaskB</a></span></code>
<div class="block">auxiliary helper class, NOT part of the API.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>(package private) static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.FFNNMultiEvalTaskB.html" title="class in popt4jlib.neural">FFNN4TrainB.FFNNMultiEvalTaskB</a></span></code>
<div class="block">static auxiliary class not part of the public API.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="nested.classes.inherited.from.class.popt4jlib.neural.FFNN4Train">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from class&nbsp;popt4jlib.neural.<a href="../../popt4jlib/neural/FFNN4Train.html" title="class in popt4jlib.neural">FFNN4Train</a></h3>
<code><a href="../../popt4jlib/neural/FFNN4Train.FFNNMultiEvalTask.html" title="class in popt4jlib.neural">FFNN4Train.FFNNMultiEvalTask</a></code></li>
</ul>
</li>
</ul>
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Field Summary table, listing fields, and an explanation">
<caption><span>Fields</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Field and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#Z:Z_computingOrderAsc">_computingOrderAsc</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private java.text.NumberFormat</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#Z:Z_df">_df</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private <a href="../../popt4jlib/BoolVector.html" title="class in popt4jlib">BoolVector</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#Z:Z_fixedWgtInds">_fixedWgtInds</a></span></code>
<div class="block">bit-vector holds indices of weights that cannot change (must remain fixed).</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#Z:Z_isInited">_isInited</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static <a href="../../utils/Messenger.html" title="class in utils">Messenger</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#Z:Z_mger">_mger</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#Z:Z_numDerivInputsPerTask">_numDerivInputsPerTask</a></span></code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="fields.inherited.from.class.popt4jlib.neural.FFNN4Train">
<!--   -->
</a>
<h3>Fields inherited from class&nbsp;popt4jlib.neural.<a href="../../popt4jlib/neural/FFNN4Train.html" title="class in popt4jlib.neural">FFNN4Train</a></h3>
<code><a href="../../popt4jlib/neural/FFNN4Train.html#Z:Z_costFunc">_costFunc</a>, <a href="../../popt4jlib/neural/FFNN4Train.html#Z:Z_extor">_extor</a>, <a href="../../popt4jlib/neural/FFNN4Train.html#Z:Z_numInputsPerTask">_numInputsPerTask</a>, <a href="../../popt4jlib/neural/FFNN4Train.html#Z:Z_numObjs4">_numObjs4</a></code></li>
</ul>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#FFNN4TrainB-java.lang.Object:A-popt4jlib.neural.OutputNNNodeIntf-popt4jlib.neural.costfunction.FFNNCostFunctionIntf-">FFNN4TrainB</a></span>(java.lang.Object[]&nbsp;hiddenlayers,
           <a href="../../popt4jlib/neural/OutputNNNodeIntf.html" title="interface in popt4jlib.neural">OutputNNNodeIntf</a>&nbsp;outputnode,
           <a href="../../popt4jlib/neural/costfunction/FFNNCostFunctionIntf.html" title="interface in popt4jlib.neural.costfunction">FFNNCostFunctionIntf</a>&nbsp;f)</code>
<div class="block">3-arg public constructor for serial training set evaluation (unless the 
 "right" params are passed to the <CODE>eval()</CODE> method.)</div>
</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#FFNN4TrainB-java.lang.Object:A-popt4jlib.neural.OutputNNNodeIntf-popt4jlib.neural.costfunction.FFNNCostFunctionIntf-int-">FFNN4TrainB</a></span>(java.lang.Object[]&nbsp;hiddenlayers,
           <a href="../../popt4jlib/neural/OutputNNNodeIntf.html" title="interface in popt4jlib.neural">OutputNNNodeIntf</a>&nbsp;outputnode,
           <a href="../../popt4jlib/neural/costfunction/FFNNCostFunctionIntf.html" title="interface in popt4jlib.neural.costfunction">FFNNCostFunctionIntf</a>&nbsp;f,
           int&nbsp;numthreads)</code>
<div class="block">4-arg public constructor allows for shared-memory parallel training set 
 evaluation.</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t1" class="tableTab"><span><a href="javascript:show(1);">Static Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#addFixedWgtInds-popt4jlib.BoolVector-">addFixedWgtInds</a></span>(<a href="../../popt4jlib/BoolVector.html" title="class in popt4jlib">BoolVector</a>&nbsp;fxdWgts)</code>
<div class="block">add the given indices as not allowed to change.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#eval-java.lang.Object-java.util.HashMap-">eval</a></span>(java.lang.Object&nbsp;x,
    java.util.HashMap&nbsp;params)</code>
<div class="block">evaluates this feed-forward neural network with single output on a given
 training dataset, with given training labels, according to the cost 
 function held in data member <CODE>_costFunction</CODE> where the cost 
 function accepts as inputs the errors of the network on the training data.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>double[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#evalGradient4TermB-double:A-double:A-double-int-">evalGradient4TermB</a></span>(double[]&nbsp;wgts,
                  double[]&nbsp;train_inst,
                  double&nbsp;train_lbl,
                  int&nbsp;num_insts)</code>
<div class="block">evaluates the entire gradient of this feed-forward neural network on a 
 single training pair (x,y).</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#evalNetworkCostOnValidationData-double:A-double:A:A-double:A-">evalNetworkCostOnValidationData</a></span>(double[]&nbsp;weights,
                               double[][]&nbsp;valdata,
                               double[]&nbsp;vallabels)</code>
<div class="block">measures network cost on validation data, using the <CODE>_costFunc</CODE>
 of this network as cost estimator.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#evalNetworkOnInputData-java.lang.Object-java.util.HashMap-">evalNetworkOnInputData</a></span>(java.lang.Object&nbsp;arg,
                      java.util.HashMap&nbsp;params)</code>
<div class="block">allows clients to call the base-class <CODE>eval()</CODE> method.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#evalNetworkOutputOnTrainingData-double:A-double:A-double-java.util.HashMap-">evalNetworkOutputOnTrainingData</a></span>(double[]&nbsp;weights,
                               double[]&nbsp;train_instance,
                               double&nbsp;train_label,
                               java.util.HashMap&nbsp;params)</code>
<div class="block">evaluates the output of the output node of the network when an input 
 (train_instance, train_label) pair is given.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#evalNetworkOutputOnValidationData-double:A-double:A:A-double:A-popt4jlib.FunctionIntf-">evalNetworkOutputOnValidationData</a></span>(double[]&nbsp;weights,
                                 double[][]&nbsp;valdata,
                                 double[]&nbsp;vallabels,
                                 <a href="../../popt4jlib/FunctionIntf.html" title="interface in popt4jlib">FunctionIntf</a>&nbsp;cf)</code>
<div class="block">measures total network cost on validation data, by computing the true 
 network output (not train error that is output during training) on these
 validation data and labels, using a cost function as cost estimator.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#evalPartialDerivativeB-double:A-int-java.util.HashMap-boolean-">evalPartialDerivativeB</a></span>(double[]&nbsp;weights,
                      int&nbsp;index,
                      java.util.HashMap&nbsp;p,
                      boolean&nbsp;clearParams)</code>
<div class="block">compute the partial derivative of the entire network with respect to the 
 weight variable indexed by index.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#finalizeInitialization-int-">finalizeInitialization</a></span>(int&nbsp;num_input_signals)</code>
<div class="block">finalize this FFNN4TrainB network's initialization by setting every node to
 belong to this network.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#fixWgtsAtValue-double:A-popt4jlib.BoolVector-double-">fixWgtsAtValue</a></span>(double[]&nbsp;wgts,
              <a href="../../popt4jlib/BoolVector.html" title="class in popt4jlib">BoolVector</a>&nbsp;wgt_inds,
              double&nbsp;val)</code>
<div class="block">sets all values of the specified weight indices in the wgt_inds bit vector
 in the wgts array to the value val, and sets the fixed weight indices to 
 the given bit vector.</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code><a href="../../popt4jlib/neural/NNNodeIntf.html" title="interface in popt4jlib.neural">NNNodeIntf</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#getEndNode-int-int-">getEndNode</a></span>(int&nbsp;numInputSignals,
          int&nbsp;weightIndex)</code>
<div class="block">get the NNNodeIntf node that is the "sink" of the weight whose index is
 the given 2nd argument.</div>
</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code><a href="../../popt4jlib/BoolVector.html" title="class in popt4jlib">BoolVector</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#getFixedWgtInds--">getFixedWgtInds</a></span>()</code>
<div class="block">gets the weight indices that are currently fixed (are not allowed to 
 change.)</div>
</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code>int[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#getIndices4BiasInWgts-int-">getIndices4BiasInWgts</a></span>(int&nbsp;num_input_signals)</code>
<div class="block">return an int[] containing the indices of the bias terms in the all weights
 variables for this network.</div>
</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code><a href="../../popt4jlib/neural/NNNodeIntf.html" title="interface in popt4jlib.neural">NNNodeIntf</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#getStartNode-int-int-">getStartNode</a></span>(int&nbsp;numInputSignals,
            int&nbsp;weightIndex)</code>
<div class="block">get the NNNodeIntf node that is the "source" of the weight whose index is
 the given 2nd argument.</div>
</td>
</tr>
<tr id="i14" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#getTotalNumWeights--">getTotalNumWeights</a></span>()</code>
<div class="block">get the total number of weights variables (including biases) for this net.</div>
</td>
</tr>
<tr id="i15" class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#isInitialized--">isInitialized</a></span>()</code>
<div class="block">synchronized method that returns true if and only if the 
 <CODE>finalizeInitialization(num)</CODE> method has been called on this
 object.</div>
</td>
</tr>
<tr id="i16" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#main-java.lang.String:A-">main</a></span>(java.lang.String[]&nbsp;args)</code>
<div class="block">invoke as:
 <CODE>
 java -cp &lt;classpath&gt; popt4jlib.neural.FFNN4TrainB 
 &lt;params_file&gt; [num_threads(1)]
 </CODE>.</div>
</td>
</tr>
<tr id="i17" class="rowColor">
<td class="colFirst"><code>private void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#resetDerivCaches--">resetDerivCaches</a></span>()</code>
<div class="block">resets the derivative-related cache of every node in this ffnn.</div>
</td>
</tr>
<tr id="i18" class="altColor">
<td class="colFirst"><code>private void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#resetGradVectorCaches--">resetGradVectorCaches</a></span>()</code>
<div class="block">resets the gradient vector cache of every node in this ffnn.</div>
</td>
</tr>
<tr id="i19" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#setComputingOrderAsc-boolean-">setComputingOrderAsc</a></span>(boolean&nbsp;do_asc)</code>
<div class="block">sets the order in which the partial derivatives are to be computed in the 
 method <CODE>evalGradient4TermB()</CODE>.</div>
</td>
</tr>
<tr id="i20" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/FFNN4TrainB.html#setFixedWgtInds-popt4jlib.BoolVector-">setFixedWgtInds</a></span>(<a href="../../popt4jlib/BoolVector.html" title="class in popt4jlib">BoolVector</a>&nbsp;fixedInds)</code>
<div class="block">sets the weight indices that are not currently allowed to change.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.popt4jlib.neural.FFNN">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;popt4jlib.neural.<a href="../../popt4jlib/neural/FFNN.html" title="class in popt4jlib.neural">FFNN</a></h3>
<code><a href="../../popt4jlib/neural/FFNN.html#getHiddenLayers--">getHiddenLayers</a>, <a href="../../popt4jlib/neural/FFNN.html#getLayerWeights-int-double:A-int-">getLayerWeights</a>, <a href="../../popt4jlib/neural/FFNN.html#getLayerWeightsWithBias-int-double:A-int-">getLayerWeightsWithBias</a>, <a href="../../popt4jlib/neural/FFNN.html#getNumHiddenLayers--">getNumHiddenLayers</a>, <a href="../../popt4jlib/neural/FFNN.html#getOutputNode--">getOutputNode</a>, <a href="../../popt4jlib/neural/FFNN.html#getOutputWeights-double:A-">getOutputWeights</a>, <a href="../../popt4jlib/neural/FFNN.html#getOutputWeightsWithBias-double:A-">getOutputWeightsWithBias</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.detail">
<!--   -->
</a>
<h3>Field Detail</h3>
<a name="Z:Z_numDerivInputsPerTask">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_numDerivInputsPerTask</h4>
<pre>private static final&nbsp;int _numDerivInputsPerTask</pre>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../constant-values.html#popt4jlib.neural.FFNN4TrainB._numDerivInputsPerTask">Constant Field Values</a></dd>
</dl>
</li>
</ul>
<a name="Z:Z_df">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_df</h4>
<pre>private&nbsp;java.text.NumberFormat _df</pre>
</li>
</ul>
<a name="Z:Z_mger">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_mger</h4>
<pre>private static final&nbsp;<a href="../../utils/Messenger.html" title="class in utils">Messenger</a> _mger</pre>
</li>
</ul>
<a name="Z:Z_isInited">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_isInited</h4>
<pre>private&nbsp;boolean _isInited</pre>
</li>
</ul>
<a name="Z:Z_computingOrderAsc">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_computingOrderAsc</h4>
<pre>private&nbsp;boolean _computingOrderAsc</pre>
</li>
</ul>
<a name="Z:Z_fixedWgtInds">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>_fixedWgtInds</h4>
<pre>private&nbsp;<a href="../../popt4jlib/BoolVector.html" title="class in popt4jlib">BoolVector</a> _fixedWgtInds</pre>
<div class="block">bit-vector holds indices of weights that cannot change (must remain fixed).
 Notice that ALL methods handling this bit-vector are unsynchronized and 
 therefore it is only safe to use them from the "main" thread of control
 before passing <CODE>FFNNMultiEvalTaskB</CODE> and/or 
 <CODE>FFNNMultiEvalPartialDerivTaskB</CODE> objects to compute the 
 neural network function value or the derivative of the neural network.</div>
</li>
</ul>
</li>
</ul>
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="FFNN4TrainB-java.lang.Object:A-popt4jlib.neural.OutputNNNodeIntf-popt4jlib.neural.costfunction.FFNNCostFunctionIntf-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>FFNN4TrainB</h4>
<pre>public&nbsp;FFNN4TrainB(java.lang.Object[]&nbsp;hiddenlayers,
                   <a href="../../popt4jlib/neural/OutputNNNodeIntf.html" title="interface in popt4jlib.neural">OutputNNNodeIntf</a>&nbsp;outputnode,
                   <a href="../../popt4jlib/neural/costfunction/FFNNCostFunctionIntf.html" title="interface in popt4jlib.neural.costfunction">FFNNCostFunctionIntf</a>&nbsp;f)</pre>
<div class="block">3-arg public constructor for serial training set evaluation (unless the 
 "right" params are passed to the <CODE>eval()</CODE> method.)</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>hiddenlayers</code> - Object[]  // NodeIntf[][]</dd>
<dd><code>outputnode</code> - OutputNNNodeIntf</dd>
<dd><code>f</code> - FFNNCostFunctionIntf the cost (error) function to measure the 
 "cost" of the network as a function of its errors on the training set; 
 if null, the MSSE is used by default (essentially corresponding to a 
 regression problem).</dd>
</dl>
</li>
</ul>
<a name="FFNN4TrainB-java.lang.Object:A-popt4jlib.neural.OutputNNNodeIntf-popt4jlib.neural.costfunction.FFNNCostFunctionIntf-int-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>FFNN4TrainB</h4>
<pre>public&nbsp;FFNN4TrainB(java.lang.Object[]&nbsp;hiddenlayers,
                   <a href="../../popt4jlib/neural/OutputNNNodeIntf.html" title="interface in popt4jlib.neural">OutputNNNodeIntf</a>&nbsp;outputnode,
                   <a href="../../popt4jlib/neural/costfunction/FFNNCostFunctionIntf.html" title="interface in popt4jlib.neural.costfunction">FFNNCostFunctionIntf</a>&nbsp;f,
                   int&nbsp;numthreads)</pre>
<div class="block">4-arg public constructor allows for shared-memory parallel training set 
 evaluation.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>hiddenlayers</code> - Object[]  // NodeIntf[][]</dd>
<dd><code>outputnode</code> - OutputNNNodeIntf</dd>
<dd><code>f</code> - FFNNCostFunctionIntf the cost (error) function to measure the 
 "cost" of the network as a function of its errors on the training set; 
 if null, the MSSE norm is used by default (essentially corresponding to a 
 regression problem).</dd>
<dd><code>numthreads</code> - int if &gt; 1, parallel training set evaluation occurs.</dd>
</dl>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="finalizeInitialization-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>finalizeInitialization</h4>
<pre>public&nbsp;void&nbsp;finalizeInitialization(int&nbsp;num_input_signals)</pre>
<div class="block">finalize this FFNN4TrainB network's initialization by setting every node to
 belong to this network. Must be called once, right after construction of 
 this object.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>num_input_signals</code> - int the number of input signals for this network.</dd>
</dl>
</li>
</ul>
<a name="isInitialized--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isInitialized</h4>
<pre>public&nbsp;boolean&nbsp;isInitialized()</pre>
<div class="block">synchronized method that returns true if and only if the 
 <CODE>finalizeInitialization(num)</CODE> method has been called on this
 object.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>boolean</dd>
</dl>
</li>
</ul>
<a name="getTotalNumWeights--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getTotalNumWeights</h4>
<pre>public&nbsp;int&nbsp;getTotalNumWeights()</pre>
<div class="block">get the total number of weights variables (including biases) for this net.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="getIndices4BiasInWgts-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getIndices4BiasInWgts</h4>
<pre>public&nbsp;int[]&nbsp;getIndices4BiasInWgts(int&nbsp;num_input_signals)</pre>
<div class="block">return an int[] containing the indices of the bias terms in the all weights
 variables for this network.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>num_input_signals</code> - int</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>int[] values in {0, ..., all_weights.length-1}</dd>
</dl>
</li>
</ul>
<a name="getStartNode-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getStartNode</h4>
<pre>public&nbsp;<a href="../../popt4jlib/neural/NNNodeIntf.html" title="interface in popt4jlib.neural">NNNodeIntf</a>&nbsp;getStartNode(int&nbsp;numInputSignals,
                               int&nbsp;weightIndex)</pre>
<div class="block">get the NNNodeIntf node that is the "source" of the weight whose index is
 the given 2nd argument.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>numInputSignals</code> - int the number of input features in this FFNN4TrainB
 object</dd>
<dd><code>weightIndex</code> - int</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>NNNodeIntf may be null if weight connects input features to 1st 
 hidden layer or if weight is for bias term</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code>java.lang.IllegalArgumentException</code> - if weightIndex is invalid</dd>
</dl>
</li>
</ul>
<a name="getEndNode-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getEndNode</h4>
<pre>public&nbsp;<a href="../../popt4jlib/neural/NNNodeIntf.html" title="interface in popt4jlib.neural">NNNodeIntf</a>&nbsp;getEndNode(int&nbsp;numInputSignals,
                             int&nbsp;weightIndex)</pre>
<div class="block">get the NNNodeIntf node that is the "sink" of the weight whose index is
 the given 2nd argument.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>numInputSignals</code> - int the number of input features in this FFNN4TrainB
 object</dd>
<dd><code>weightIndex</code> - int</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>NNNodeIntf</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code>java.lang.IllegalArgumentException</code> - if weightIndex is invalid</dd>
</dl>
</li>
</ul>
<a name="getFixedWgtInds--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getFixedWgtInds</h4>
<pre>public&nbsp;<a href="../../popt4jlib/BoolVector.html" title="class in popt4jlib">BoolVector</a>&nbsp;getFixedWgtInds()</pre>
<div class="block">gets the weight indices that are currently fixed (are not allowed to 
 change.)</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>BoolVector</dd>
</dl>
</li>
</ul>
<a name="setFixedWgtInds-popt4jlib.BoolVector-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setFixedWgtInds</h4>
<pre>public&nbsp;void&nbsp;setFixedWgtInds(<a href="../../popt4jlib/BoolVector.html" title="class in popt4jlib">BoolVector</a>&nbsp;fixedInds)</pre>
<div class="block">sets the weight indices that are not currently allowed to change.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>fixedInds</code> - BoolVector</dd>
</dl>
</li>
</ul>
<a name="addFixedWgtInds-popt4jlib.BoolVector-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>addFixedWgtInds</h4>
<pre>public&nbsp;void&nbsp;addFixedWgtInds(<a href="../../popt4jlib/BoolVector.html" title="class in popt4jlib">BoolVector</a>&nbsp;fxdWgts)</pre>
<div class="block">add the given indices as not allowed to change. Previous weight indices 
 that were fixed, remain fixed.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>fxdWgts</code> - BoolVector</dd>
</dl>
</li>
</ul>
<a name="fixWgtsAtValue-double:A-popt4jlib.BoolVector-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fixWgtsAtValue</h4>
<pre>public&nbsp;void&nbsp;fixWgtsAtValue(double[]&nbsp;wgts,
                           <a href="../../popt4jlib/BoolVector.html" title="class in popt4jlib">BoolVector</a>&nbsp;wgt_inds,
                           double&nbsp;val)</pre>
<div class="block">sets all values of the specified weight indices in the wgt_inds bit vector
 in the wgts array to the value val, and sets the fixed weight indices to 
 the given bit vector.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>wgts</code> - double[] must be of same size as wgt_inds bit vector</dd>
<dd><code>wgt_inds</code> - BoolVector must be of same size as wgts double array</dd>
<dd><code>val</code> - double (usually zero)</dd>
</dl>
</li>
</ul>
<a name="evalNetworkOnInputData-java.lang.Object-java.util.HashMap-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evalNetworkOnInputData</h4>
<pre>public&nbsp;double&nbsp;evalNetworkOnInputData(java.lang.Object&nbsp;arg,
                                     java.util.HashMap&nbsp;params)</pre>
<div class="block">allows clients to call the base-class <CODE>eval()</CODE> method.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Overrides:</span></dt>
<dd><code><a href="../../popt4jlib/neural/FFNN4Train.html#evalNetworkOnInputData-java.lang.Object-java.util.HashMap-">evalNetworkOnInputData</a></code>&nbsp;in class&nbsp;<code><a href="../../popt4jlib/neural/FFNN4Train.html" title="class in popt4jlib.neural">FFNN4Train</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>arg</code> - Object  // double[] inputSignal</dd>
<dd><code>params</code> - HashMap  // must contain &lt;"hiddenws$i$", double[][]&gt;
 as well as &lt;"outputws",double[]&gt; pairs. All these arrays must be
 expanded to include the respective node biases.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double</dd>
</dl>
</li>
</ul>
<a name="evalNetworkOutputOnTrainingData-double:A-double:A-double-java.util.HashMap-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evalNetworkOutputOnTrainingData</h4>
<pre>public&nbsp;double&nbsp;evalNetworkOutputOnTrainingData(double[]&nbsp;weights,
                                              double[]&nbsp;train_instance,
                                              double&nbsp;train_label,
                                              java.util.HashMap&nbsp;params)</pre>
<div class="block">evaluates the output of the output node of the network when an input 
 (train_instance, train_label) pair is given.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>weights</code> - double[] all weights array (includes bias terms)</dd>
<dd><code>train_instance</code> - double[] the training instance</dd>
<dd><code>train_label</code> - double the training label</dd>
<dd><code>params</code> - HashMap unused</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double</dd>
</dl>
</li>
</ul>
<a name="evalNetworkCostOnValidationData-double:A-double:A:A-double:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evalNetworkCostOnValidationData</h4>
<pre>public&nbsp;double&nbsp;evalNetworkCostOnValidationData(double[]&nbsp;weights,
                                              double[][]&nbsp;valdata,
                                              double[]&nbsp;vallabels)</pre>
<div class="block">measures network cost on validation data, using the <CODE>_costFunc</CODE>
 of this network as cost estimator. Clears all caches before and after every
 computation (operation is not really needed.) Can be easily parallelized as 
 well.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>weights</code> - double[] the weights of the network</dd>
<dd><code>valdata</code> - double[][] the validation instances</dd>
<dd><code>vallabels</code> - double[] the validation labels</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double</dd>
</dl>
</li>
</ul>
<a name="evalNetworkOutputOnValidationData-double:A-double:A:A-double:A-popt4jlib.FunctionIntf-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evalNetworkOutputOnValidationData</h4>
<pre>public&nbsp;double&nbsp;evalNetworkOutputOnValidationData(double[]&nbsp;weights,
                                                double[][]&nbsp;valdata,
                                                double[]&nbsp;vallabels,
                                                <a href="../../popt4jlib/FunctionIntf.html" title="interface in popt4jlib">FunctionIntf</a>&nbsp;cf)</pre>
<div class="block">measures total network cost on validation data, by computing the true 
 network output (not train error that is output during training) on these
 validation data and labels, using a cost function as cost estimator. This 
 is the main method for measuring validation accuracy of the network after 
 it has been trained.
 Can be easily parallelized as well.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>weights</code> - double[] the weights of the network</dd>
<dd><code>valdata</code> - double[][] the validation instances</dd>
<dd><code>vallabels</code> - double[] the validation labels</dd>
<dd><code>cf</code> - FunctionIntf the function used to measure the total cost on the 
 errors; if null, the <CODE>_costFunc</CODE> of this object is used.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double</dd>
</dl>
</li>
</ul>
<a name="eval-java.lang.Object-java.util.HashMap-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>eval</h4>
<pre>public&nbsp;double&nbsp;eval(java.lang.Object&nbsp;x,
                   java.util.HashMap&nbsp;params)</pre>
<div class="block">evaluates this feed-forward neural network with single output on a given
 training dataset, with given training labels, according to the cost 
 function held in data member <CODE>_costFunction</CODE> where the cost 
 function accepts as inputs the errors of the network on the training data.
 The difference from base class <CODE>FFNN4Train</CODE> is that in this 
 class, each node requires one more weight (coming last in the order of 
 weights) to be the bias for the node), so the weights variables array must
 have size increased by exactly the number of total nodes (hidden plus 
 output) in the network.
 The network can also be trained with random mini-batches if the key-value
 pair &lt;"ffnn.randombatchsize",$num$&gt; exists in the parameters hashmap
 passed in as second argument to the method call; in such a case, only a 
 random sample from the training set of the given size will be used to
 evaluate the network, which of course will significantly speed-up training.
 On the other hand, this will also make the call to this function with the
 same arguments non-deterministic as same weights and same parameters will
 be evaluated on a different training sample. Further, when only a strict
 subset of the entire training set is evaluated, the resulting errors array
 although it has length equal to the entire training set size, it will 
 contain NaN's for those instances that were not evaluated, and in the case
 of parallel execution, the errors will not in general correspond to the 
 positions in the training set that they were created. This should not 
 create any problem for cost function evaluation, because no cost function 
 cares about where an error has occurred (see the classes in package 
 <CODE>popt4jlib.neural.costfunction</CODE>).</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../popt4jlib/FunctionIntf.html#eval-java.lang.Object-java.util.HashMap-">eval</a></code>&nbsp;in interface&nbsp;<code><a href="../../popt4jlib/FunctionIntf.html" title="interface in popt4jlib">FunctionIntf</a></code></dd>
<dt><span class="overrideSpecifyLabel">Overrides:</span></dt>
<dd><code><a href="../../popt4jlib/neural/FFNN4Train.html#eval-java.lang.Object-java.util.HashMap-">eval</a></code>&nbsp;in class&nbsp;<code><a href="../../popt4jlib/neural/FFNN4Train.html" title="class in popt4jlib.neural">FFNN4Train</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x</code> - Object  // double[] the weights of the network:
 The weights are stored consecutively, starting with the weights of the 
 first node of the first layer (including for each node one bias variable), 
 then continuing with the weights of the second node of the first layer 
 (again, including one bias variable for each node) ... until finally we get 
 the weights of the connections to the output node plus their own biases. 
 The FFNN class network architecture is that all nodes in one layer connect 
 to all nodes in the next layer and only those. Notice that x may be instead 
 be a <CODE>DblArray1Vector</CODE> object, in which case we obtain access to 
 the underlying <CODE>double[]</CODE> via the 
 <CODE>popt4jlib.DblArray1VectorAccess.get_x()</CODE> static method.</dd>
<dd><code>params</code> - HashMap must contain the dataset as well as the labels for
 each input vector. The dataset is maintained as a 2-D double array
 <CODE>double[][]</CODE> with key "ffnn.traindata" where each row represents 
 one input vector, together with the expected outputs maintained in a 1-D 
 double array <CODE>double[]</CODE> stored for key "ffnn.trainlabels". If 
 either of these two keys doesn't exist in the params map, the method will
 attempt to retrieve them by calling the static class methods
 <CODE>TrainData.getTrainingVectors()</CODE> and/or 
 <CODE>TrainData.getTrainingLabels()</CODE> respectively. In the case of
 distributed function evaluations (where both the weights as well as the 
 parameters needed for the evaluation of the function) this allows to avoid
 sending the training data along with the weights for evaluation over the 
 network, assuming of course that when the argument reaches its destination
 worker JVM, the worker has been initialized via a proper command so that 
 the calls mentioned above actually have (cached) data to return.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double</dd>
</dl>
</li>
</ul>
<a name="evalPartialDerivativeB-double:A-int-java.util.HashMap-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evalPartialDerivativeB</h4>
<pre>public&nbsp;double&nbsp;evalPartialDerivativeB(double[]&nbsp;weights,
                                     int&nbsp;index,
                                     java.util.HashMap&nbsp;p,
                                     boolean&nbsp;clearParams)</pre>
<div class="block">compute the partial derivative of the entire network with respect to the 
 weight variable indexed by index. Before calling this method, the 
 <CODE>finalizeInitialization(n)</CODE> method must have been called first
 on this object to set up the nodes in the neural net.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>weights</code> - double[] the values array for the variables of the function</dd>
<dd><code>index</code> - int the index of the function to compute its partial 
 derivative at (range in {0,1,...weights.length-1})</dd>
<dd><code>p</code> - HashMap must contain the "ffnn.traindata" and "ffnn.trainlabels"
 keys, else the data will be fetched from the <CODE>TrainData</CODE> class.</dd>
<dd><code>clearParams</code> - boolean if true, any "hiddenws$i$" and "outputws" keys
 will be removed from the parameters p hashmap that is passed to the nodes
 of the neural network for automatic differentiation. Notice that this 
 parameter must become true when the weights argument no longer corresponds
 to the keys mentioned above in the hashmap, but should otherwise be false.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double</dd>
</dl>
</li>
</ul>
<a name="setComputingOrderAsc-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setComputingOrderAsc</h4>
<pre>public&nbsp;void&nbsp;setComputingOrderAsc(boolean&nbsp;do_asc)</pre>
<div class="block">sets the order in which the partial derivatives are to be computed in the 
 method <CODE>evalGradient4TermB()</CODE>.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>do_asc</code> - boolean</dd>
</dl>
</li>
</ul>
<a name="evalGradient4TermB-double:A-double:A-double-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evalGradient4TermB</h4>
<pre>public&nbsp;double[]&nbsp;evalGradient4TermB(double[]&nbsp;wgts,
                                   double[]&nbsp;train_inst,
                                   double&nbsp;train_lbl,
                                   int&nbsp;num_insts)</pre>
<div class="block">evaluates the entire gradient of this feed-forward neural network on a 
 single training pair (x,y). The order of computing the partial derivatives
 is by default descending, meaning that the derivatives corresponding to the
 first hidden layer's weights will be computed last, but can be reversed
 by calling the method <CODE>setComputingOrderAsc(true)</CODE> of this 
 object before calling this method.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>wgts</code> - double[] the point at which to compute automatically the 
 derivative</dd>
<dd><code>train_inst</code> - double[] the training instance x</dd>
<dd><code>train_lbl</code> - double the training label y</dd>
<dd><code>num_insts</code> - int the total number of training instances</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double[] the gradient of this network on the point wgts given the 
 training pair (train_inst, train_lbl)</dd>
</dl>
</li>
</ul>
<a name="resetDerivCaches--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>resetDerivCaches</h4>
<pre>private&nbsp;void&nbsp;resetDerivCaches()</pre>
<div class="block">resets the derivative-related cache of every node in this ffnn.</div>
</li>
</ul>
<a name="resetGradVectorCaches--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>resetGradVectorCaches</h4>
<pre>private&nbsp;void&nbsp;resetGradVectorCaches()</pre>
<div class="block">resets the gradient vector cache of every node in this ffnn.</div>
</li>
</ul>
<a name="main-java.lang.String:A-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>main</h4>
<pre>public static&nbsp;void&nbsp;main(java.lang.String[]&nbsp;args)</pre>
<div class="block">invoke as:
 <CODE>
 java -cp &lt;classpath&gt; popt4jlib.neural.FFNN4TrainB 
 &lt;params_file&gt; [num_threads(1)]
 </CODE>.
 <PRE>
 The params file is a file that should contain at least the "hiddenlayers"
 "outputlayer", "ffnn.traindata" and "ffnn.trainlabels" params; for example:
 # the following defines an ANN and weights on the nn's connections
 # the ANN looks like this:
 # INP L0   L1   OUT
 # x1
 # x2  N00  N10  y
 # x3  N01  N11
 # x4       N12
 class,n00,popt4jlib.neural.ReLU
 class,n01,popt4jlib.neural.ReLU
 class,n10,popt4jlib.neural.ReLU
 class,n11,popt4jlib.neural.ReLU
 class,n12,popt4jlib.neural.ReLU
 class,outputlayer,popt4jlib.neural.HardThres,0.0
 array,layer1_arr,popt4jlib.neural.NNNodeIntf,n00,n01
 array,layer2_arr,popt4jlib.neural.NNNodeIntf,n10,n11,n12
 array,hiddenlayers,[Ljava.lang.Object;,layer1_arr,layer2_arr
 matrix,ffnn.traindata,testdata/traindata0.dat
 dblarray,ffnn.trainlabels,testdata/trainlabels0.dat
 array,weights,double, 1,1,0,0,0, 0,0,0,0,0, 1,1,0, 1,1,0, 0,0,0, 1,1,1,1 
 </PRE>
 The training data file is a data file that describes a matrix in a format
 readable by the method <CODE>utils.DataMgr.readMatrixFromFile()</CODE>;each
 row of the matrix corresponds to one training vector. The columns of the
 matrix correspond to the features (attributes) of the problem at hand.
 The training labels file is a text file that contains one (double) value in
 each line, and can be read by the method 
 <CODE>utils.DataMgr.readDoubleLabelsFromFile(filename)</CODE>.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>args</code> - String[] only the params filename arg is required.</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="class-use/FFNN4TrainB.html">Use</a></li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../index-files/index-1.html">Index</a></li>
<li><a href="../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../popt4jlib/neural/FFNN4Train.FFNNMultiEvalTask.html" title="class in popt4jlib.neural"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../popt4jlib/neural/FFNN4TrainB.FFNNMultiEvalPartialDerivTaskB.html" title="class in popt4jlib.neural"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../index.html?popt4jlib/neural/FFNN4TrainB.html" target="_top">Frames</a></li>
<li><a href="FFNN4TrainB.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.class.summary">Nested</a>&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
