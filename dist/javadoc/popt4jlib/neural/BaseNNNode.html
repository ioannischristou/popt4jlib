<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_144) on Sun Jun 06 12:43:15 EEST 2021 -->
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>BaseNNNode</title>
<meta name="date" content="2021-06-06">
<link rel="stylesheet" type="text/css" href="../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="BaseNNNode";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":10,"i2":10,"i3":10,"i4":10,"i5":10,"i6":10,"i7":10,"i8":10,"i9":10,"i10":10,"i11":10,"i12":10,"i13":10,"i14":10,"i15":10,"i16":10,"i17":10,"i18":10,"i19":10,"i20":10,"i21":10,"i22":10,"i23":10,"i24":10,"i25":10,"i26":10,"i27":10,"i28":10,"i29":10,"i30":10,"i31":10};
var tabs = {65535:["t0","All Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="class-use/BaseNNNode.html">Use</a></li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../index-files/index-1.html">Index</a></li>
<li><a href="../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../popt4jlib/neural/Adam4FFNN.Adam4FFNNThread.html" title="class in popt4jlib.neural"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../popt4jlib/neural/CategoricalXEntropyLoss.html" title="class in popt4jlib.neural"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../index.html?popt4jlib/neural/BaseNNNode.html" target="_top">Frames</a></li>
<li><a href="BaseNNNode.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">popt4jlib.neural</div>
<h2 title="Class BaseNNNode" class="title">Class BaseNNNode</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>popt4jlib.neural.BaseNNNode</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>Direct Known Subclasses:</dt>
<dd><a href="../../popt4jlib/neural/CategoricalXEntropyLoss.html" title="class in popt4jlib.neural">CategoricalXEntropyLoss</a>, <a href="../../popt4jlib/neural/CategoricalXEntropyLossW.html" title="class in popt4jlib.neural">CategoricalXEntropyLossW</a>, <a href="../../popt4jlib/neural/GELU.html" title="class in popt4jlib.neural">GELU</a>, <a href="../../popt4jlib/neural/HardThres.html" title="class in popt4jlib.neural">HardThres</a>, <a href="../../popt4jlib/neural/InputSignalMaxPosSelector.html" title="class in popt4jlib.neural">InputSignalMaxPosSelector</a>, <a href="../../popt4jlib/neural/Linear.html" title="class in popt4jlib.neural">Linear</a>, <a href="../../popt4jlib/neural/MultiClassSSE.html" title="class in popt4jlib.neural">MultiClassSSE</a>, <a href="../../popt4jlib/neural/Quadratic.html" title="class in popt4jlib.neural">Quadratic</a>, <a href="../../popt4jlib/neural/ReLU.html" title="class in popt4jlib.neural">ReLU</a>, <a href="../../popt4jlib/neural/Sigmoid.html" title="class in popt4jlib.neural">Sigmoid</a>, <a href="../../popt4jlib/neural/SoftPlus.html" title="class in popt4jlib.neural">SoftPlus</a>, <a href="../../popt4jlib/neural/TanH.html" title="class in popt4jlib.neural">TanH</a>, <a href="../../popt4jlib/neural/TanH01.html" title="class in popt4jlib.neural">TanH01</a>, <a href="../../popt4jlib/neural/TanHM11.html" title="class in popt4jlib.neural">TanHM11</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="typeNameLabel">BaseNNNode</span>
extends java.lang.Object</pre>
<div class="block">base class for NNNodeIntf that implements common functionalities of
 the FFNN nodes.
 <p>Title: popt4jlib</p>
 <p>Description: A Parallel Meta-Heuristic Optimization Library in Java</p>
 <p>Copyright: Copyright (c) 2011-2020</p>
 <p>Company: </p></div>
<dl>
<dt><span class="simpleTagLabel">Version:</span></dt>
<dd>1.0</dd>
<dt><span class="simpleTagLabel">Author:</span></dt>
<dd>Ioannis T. Christou</dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Field Summary table, listing fields, and an explanation">
<caption><span>Fields</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Field and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../popt4jlib/BoolVector.html" title="class in popt4jlib">BoolVector</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_antecedentWeights">_antecedentWeights</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_biasInd">_biasInd</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_endWeightInd">_endWeightInd</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../popt4jlib/neural/FFNN4TrainB.html" title="class in popt4jlib.neural">FFNN4TrainB</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_ffnn">_ffnn</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_isDropout">_isDropout</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private java.lang.ThreadLocal</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_lastDerivEvalCache">_lastDerivEvalCache</a></span></code>
<div class="block">the only caches we need: double for lastDerivEval, double[] for lastinputs
 and double for lastEval.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private java.lang.ThreadLocal</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_lastDerivEvalCache2">_lastDerivEvalCache2</a></span></code>
<div class="block">the _lastDerivEvalCache2 cache holds for a node with activation function
 f, the value f'(net_input_sum), which is constant for the same (x,y) 
 training pair.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private java.lang.ThreadLocal</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_lastEvalCache">_lastEvalCache</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private java.lang.ThreadLocal</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_lastGradVectorCache">_lastGradVectorCache</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private java.lang.ThreadLocal</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_lastInputsCache">_lastInputsCache</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_NaN">_NaN</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_nodeLayer">_nodeLayer</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_posInLayer">_posInLayer</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#Z:Z_startWeightInd">_startWeightInd</a></span></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#BaseNNNode--">BaseNNNode</a></span>()</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#addPreviousWeightsRange-int-int-">addPreviousWeightsRange</a></span>(int&nbsp;start,
                       int&nbsp;end)</code>
<div class="block">adds the indices of weight variables that are input to nodes in previous
 layers that eventually connect to this one.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#evalPartialDerivativeB-double:A-int-double:A-double-">evalPartialDerivativeB</a></span>(double[]&nbsp;weights,
                      int&nbsp;index,
                      double[]&nbsp;inputSignals,
                      double&nbsp;true_lbl)</code>
<div class="block">catch-all method for NNNodeIntf classes that do not implement this method.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#evalPartialDerivativeB-double:A-int-double:A-double-java.util.HashMap-">evalPartialDerivativeB</a></span>(double[]&nbsp;weights,
                      int&nbsp;index,
                      double[]&nbsp;inputSignals,
                      double&nbsp;true_lbl,
                      java.util.HashMap&nbsp;p)</code>
<div class="block">catch-all method for NNNodeIntf classes that do not implement this method.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#getBiasIndex--">getBiasIndex</a></span>()</code>
<div class="block">gets the index (in the all weights variable array) of the bias variable 
 connected directly as input to this node.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#getDirectInputWeightEndIndex--">getDirectInputWeightEndIndex</a></span>()</code>
<div class="block">gets the index of the last weight variable connected directly as  
 input to this node.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#getDirectInputWeightStartIndex--">getDirectInputWeightStartIndex</a></span>()</code>
<div class="block">gets the index of the first weight variable connected directly as  
 input to this node.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code><a href="../../popt4jlib/neural/FFNN4TrainB.html" title="class in popt4jlib.neural">FFNN4TrainB</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#getFFNN4TrainB--">getFFNN4TrainB</a></span>()</code>
<div class="block">get the network this node belongs to.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>protected double[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#getGradVectorCache--">getGradVectorCache</a></span>()</code>
<div class="block">get the last grad vector.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#getHiddenNodeLayer--">getHiddenNodeLayer</a></span>()</code>
<div class="block">get the layer index where this node resides.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>protected double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#getLastDerivEvalCache--">getLastDerivEvalCache</a></span>()</code>
<div class="block">get the last derivative evaluation.</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code>protected double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#getLastDerivEvalCache2--">getLastDerivEvalCache2</a></span>()</code>
<div class="block">get the last derivative evaluation that is for use with grad-vector caches.</div>
</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#getLastEvalCache--">getLastEvalCache</a></span>()</code>
<div class="block">get the last evaluation.</div>
</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code>double[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#getLastInputsCache--">getLastInputsCache</a></span>()</code>
<div class="block">get the last inputs.</div>
</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#getNodeLayer--">getNodeLayer</a></span>()</code>
<div class="block">get the layer number of this node in the FFNN (</div>
</td>
</tr>
<tr id="i14" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#getPositionInLayer--">getPositionInLayer</a></span>()</code>
<div class="block">returns the position index of this node in the layer it's part of in the 
 FFNN.</div>
</td>
</tr>
<tr id="i15" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#getTotalNumWeights--">getTotalNumWeights</a></span>()</code>
<div class="block">return the total number of weight variables (including bias terms) for the 
 network this node belongs to.</div>
</td>
</tr>
<tr id="i16" class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#isDropout--">isDropout</a></span>()</code>
<div class="block">gets the dropout property of this node.</div>
</td>
</tr>
<tr id="i17" class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#isWeightVariableAntecedent-int-">isWeightVariableAntecedent</a></span>(int&nbsp;index)</code>
<div class="block">returns true if and only if the index represented a connection weight that
 connects to a node that is eventually connected to this node.</div>
</td>
</tr>
<tr id="i18" class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#resetCache--">resetCache</a></span>()</code>
<div class="block">reset the cache(s) of this node.</div>
</td>
</tr>
<tr id="i19" class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#resetGradVectorCache--">resetGradVectorCache</a></span>()</code>
<div class="block">reset all components of the grad vector cache of this node to NaN values.</div>
</td>
</tr>
<tr id="i20" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#setDropout-boolean-">setDropout</a></span>(boolean&nbsp;val)</code>
<div class="block">sets the dropout property of this node.</div>
</td>
</tr>
<tr id="i21" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#setFFNN4TrainB-popt4jlib.neural.FFNN4TrainB-">setFFNN4TrainB</a></span>(<a href="../../popt4jlib/neural/FFNN4TrainB.html" title="class in popt4jlib.neural">FFNN4TrainB</a>&nbsp;ffnn)</code>
<div class="block">set the network this node belongs to.</div>
</td>
</tr>
<tr id="i22" class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#setGradVectorCache-double:A-">setGradVectorCache</a></span>(double[]&nbsp;g)</code>
<div class="block">update the last grad vector of this node.</div>
</td>
</tr>
<tr id="i23" class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#setGradVectorCache-int-double-">setGradVectorCache</a></span>(int&nbsp;i,
                  double&nbsp;gi)</code>
<div class="block">set the i-th coordinate of the last grad vector of this node.</div>
</td>
</tr>
<tr id="i24" class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#setLastDerivEvalCache-double-">setLastDerivEvalCache</a></span>(double&nbsp;val)</code>
<div class="block">cache last derivative evaluation.</div>
</td>
</tr>
<tr id="i25" class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#setLastDerivEvalCache2-double-">setLastDerivEvalCache2</a></span>(double&nbsp;val)</code>
<div class="block">cache last derivative evaluation for use with the grad-vector caches.</div>
</td>
</tr>
<tr id="i26" class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#setLastEvalCache-double-">setLastEvalCache</a></span>(double&nbsp;val)</code>
<div class="block">cache last evaluation.</div>
</td>
</tr>
<tr id="i27" class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#setLastInputsCache-double:A-">setLastInputsCache</a></span>(double[]&nbsp;inputs)</code>
<div class="block">cache last inputs.</div>
</td>
</tr>
<tr id="i28" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#setNodeLayer-int-">setNodeLayer</a></span>(int&nbsp;layerno)</code>
<div class="block">sets the layer in the FFNN that this node belongs to.</div>
</td>
</tr>
<tr id="i29" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#setPositionInLayer-int-">setPositionInLayer</a></span>(int&nbsp;pos_in_layer)</code>
<div class="block">sets the position of this node in the layer containing it.</div>
</td>
</tr>
<tr id="i30" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#setTotalNumWeights-int-">setTotalNumWeights</a></span>(int&nbsp;num_weights)</code>
<div class="block">sets the total number of variables (weights plus biases) for the FFNN that
 this node participates in.</div>
</td>
</tr>
<tr id="i31" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../popt4jlib/neural/BaseNNNode.html#setWeightRange-int-int-">setWeightRange</a></span>(int&nbsp;start,
              int&nbsp;end)</code>
<div class="block">sets the range of indices in the weights vector variable that are fed into
 this node.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.detail">
<!--   -->
</a>
<h3>Field Detail</h3>
<a name="Z:Z_startWeightInd">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_startWeightInd</h4>
<pre>protected&nbsp;int _startWeightInd</pre>
</li>
</ul>
<a name="Z:Z_endWeightInd">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_endWeightInd</h4>
<pre>protected&nbsp;int _endWeightInd</pre>
</li>
</ul>
<a name="Z:Z_biasInd">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_biasInd</h4>
<pre>protected&nbsp;int _biasInd</pre>
</li>
</ul>
<a name="Z:Z_antecedentWeights">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_antecedentWeights</h4>
<pre>protected&nbsp;<a href="../../popt4jlib/BoolVector.html" title="class in popt4jlib">BoolVector</a> _antecedentWeights</pre>
</li>
</ul>
<a name="Z:Z_nodeLayer">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_nodeLayer</h4>
<pre>private&nbsp;int _nodeLayer</pre>
</li>
</ul>
<a name="Z:Z_posInLayer">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_posInLayer</h4>
<pre>private&nbsp;int _posInLayer</pre>
</li>
</ul>
<a name="Z:Z_isDropout">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_isDropout</h4>
<pre>private volatile&nbsp;boolean _isDropout</pre>
</li>
</ul>
<a name="Z:Z_ffnn">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_ffnn</h4>
<pre>protected&nbsp;<a href="../../popt4jlib/neural/FFNN4TrainB.html" title="class in popt4jlib.neural">FFNN4TrainB</a> _ffnn</pre>
</li>
</ul>
<a name="Z:Z_NaN">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_NaN</h4>
<pre>private static final&nbsp;double _NaN</pre>
</li>
</ul>
<a name="Z:Z_lastDerivEvalCache">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_lastDerivEvalCache</h4>
<pre>private&nbsp;java.lang.ThreadLocal _lastDerivEvalCache</pre>
<div class="block">the only caches we need: double for lastDerivEval, double[] for lastinputs
 and double for lastEval. Add to that the gradient vector cache stored also
 as double[].</div>
</li>
</ul>
<a name="Z:Z_lastInputsCache">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_lastInputsCache</h4>
<pre>private&nbsp;java.lang.ThreadLocal _lastInputsCache</pre>
</li>
</ul>
<a name="Z:Z_lastEvalCache">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_lastEvalCache</h4>
<pre>private&nbsp;java.lang.ThreadLocal _lastEvalCache</pre>
</li>
</ul>
<a name="Z:Z_lastGradVectorCache">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>_lastGradVectorCache</h4>
<pre>private&nbsp;java.lang.ThreadLocal _lastGradVectorCache</pre>
</li>
</ul>
<a name="Z:Z_lastDerivEvalCache2">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>_lastDerivEvalCache2</h4>
<pre>private&nbsp;java.lang.ThreadLocal _lastDerivEvalCache2</pre>
<div class="block">the _lastDerivEvalCache2 cache holds for a node with activation function
 f, the value f'(net_input_sum), which is constant for the same (x,y) 
 training pair.</div>
</li>
</ul>
</li>
</ul>
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="BaseNNNode--">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>BaseNNNode</h4>
<pre>public&nbsp;BaseNNNode()</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="setTotalNumWeights-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setTotalNumWeights</h4>
<pre>public&nbsp;void&nbsp;setTotalNumWeights(int&nbsp;num_weights)</pre>
<div class="block">sets the total number of variables (weights plus biases) for the FFNN that
 this node participates in. Must be called before any attempts at automatic
 differentiation of the network this node participates in.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>num_weights</code> - int</dd>
</dl>
</li>
</ul>
<a name="getTotalNumWeights--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getTotalNumWeights</h4>
<pre>public&nbsp;int&nbsp;getTotalNumWeights()</pre>
<div class="block">return the total number of weight variables (including bias terms) for the 
 network this node belongs to. The <CODE>finalizeInitialization(num)</CODE>
 method of the containing network must have been called first.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>int</dd>
</dl>
</li>
</ul>
<a name="setNodeLayer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setNodeLayer</h4>
<pre>public&nbsp;void&nbsp;setNodeLayer(int&nbsp;layerno)</pre>
<div class="block">sets the layer in the FFNN that this node belongs to.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerno</code> - int can be in {0,...#hidden_layers} with #hidden_layers
 indicating the output layer.</dd>
</dl>
</li>
</ul>
<a name="getNodeLayer--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getNodeLayer</h4>
<pre>public&nbsp;int&nbsp;getNodeLayer()</pre>
<div class="block">get the layer number of this node in the FFNN (</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="setPositionInLayer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setPositionInLayer</h4>
<pre>public&nbsp;void&nbsp;setPositionInLayer(int&nbsp;pos_in_layer)</pre>
<div class="block">sets the position of this node in the layer containing it.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>pos_in_layer</code> - int in {0,...,#nodes_in_layer-1}</dd>
</dl>
</li>
</ul>
<a name="getPositionInLayer--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPositionInLayer</h4>
<pre>public&nbsp;int&nbsp;getPositionInLayer()</pre>
<div class="block">returns the position index of this node in the layer it's part of in the 
 FFNN.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>int in {0,...,#nodes_in_layer-1}</dd>
</dl>
</li>
</ul>
<a name="setFFNN4TrainB-popt4jlib.neural.FFNN4TrainB-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setFFNN4TrainB</h4>
<pre>public&nbsp;void&nbsp;setFFNN4TrainB(<a href="../../popt4jlib/neural/FFNN4TrainB.html" title="class in popt4jlib.neural">FFNN4TrainB</a>&nbsp;ffnn)</pre>
<div class="block">set the network this node belongs to.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>ffnn</code> - FFNN4TrainB</dd>
</dl>
</li>
</ul>
<a name="getFFNN4TrainB--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getFFNN4TrainB</h4>
<pre>public&nbsp;<a href="../../popt4jlib/neural/FFNN4TrainB.html" title="class in popt4jlib.neural">FFNN4TrainB</a>&nbsp;getFFNN4TrainB()</pre>
<div class="block">get the network this node belongs to.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>FFNN4TrainB</dd>
</dl>
</li>
</ul>
<a name="setWeightRange-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setWeightRange</h4>
<pre>public&nbsp;void&nbsp;setWeightRange(int&nbsp;start,
                           int&nbsp;end)</pre>
<div class="block">sets the range of indices in the weights vector variable that are fed into
 this node. These are the weights that are directly input to this node and 
 includes the bias variable weight for this node (which is indexed at end.)
 It also adds these weights as antecedents to all the nodes this node 
 connects to.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>start</code> - int inclusive</dd>
<dd><code>end</code> - int inclusive</dd>
</dl>
</li>
</ul>
<a name="addPreviousWeightsRange-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>addPreviousWeightsRange</h4>
<pre>public&nbsp;void&nbsp;addPreviousWeightsRange(int&nbsp;start,
                                    int&nbsp;end)</pre>
<div class="block">adds the indices of weight variables that are input to nodes in previous
 layers that eventually connect to this one.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>start</code> - int inclusive</dd>
<dd><code>end</code> - int inclusive</dd>
</dl>
</li>
</ul>
<a name="getDirectInputWeightStartIndex--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDirectInputWeightStartIndex</h4>
<pre>public&nbsp;int&nbsp;getDirectInputWeightStartIndex()</pre>
<div class="block">gets the index of the first weight variable connected directly as  
 input to this node.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>int</dd>
</dl>
</li>
</ul>
<a name="getDirectInputWeightEndIndex--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDirectInputWeightEndIndex</h4>
<pre>public&nbsp;int&nbsp;getDirectInputWeightEndIndex()</pre>
<div class="block">gets the index of the last weight variable connected directly as  
 input to this node.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>int</dd>
</dl>
</li>
</ul>
<a name="getBiasIndex--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getBiasIndex</h4>
<pre>public&nbsp;int&nbsp;getBiasIndex()</pre>
<div class="block">gets the index (in the all weights variable array) of the bias variable 
 connected directly as input to this node.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>int</dd>
</dl>
</li>
</ul>
<a name="isWeightVariableAntecedent-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isWeightVariableAntecedent</h4>
<pre>public&nbsp;boolean&nbsp;isWeightVariableAntecedent(int&nbsp;index)</pre>
<div class="block">returns true if and only if the index represented a connection weight that
 connects to a node that is eventually connected to this node.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>index</code> - int</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>boolean</dd>
</dl>
</li>
</ul>
<a name="getHiddenNodeLayer--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getHiddenNodeLayer</h4>
<pre>public&nbsp;int&nbsp;getHiddenNodeLayer()</pre>
<div class="block">get the layer index where this node resides.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>int in [0, #hidden_layers-1] or -1 if this node is not found among
 the hidden nodes of this network (ie it's the output node)</dd>
</dl>
</li>
</ul>
<a name="evalPartialDerivativeB-double:A-int-double:A-double-java.util.HashMap-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evalPartialDerivativeB</h4>
<pre>public&nbsp;double&nbsp;evalPartialDerivativeB(double[]&nbsp;weights,
                                     int&nbsp;index,
                                     double[]&nbsp;inputSignals,
                                     double&nbsp;true_lbl,
                                     java.util.HashMap&nbsp;p)</pre>
<div class="block">catch-all method for NNNodeIntf classes that do not implement this method.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>weights</code> - double[] all variables (including biases) array</dd>
<dd><code>index</code> - int the index of the partial derivative to take</dd>
<dd><code>inputSignals</code> - double[]</dd>
<dd><code>true_lbl</code> - double</dd>
<dd><code>p</code> - HashMap includes the train-data matrix and train-labels array.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double</dd>
</dl>
</li>
</ul>
<a name="evalPartialDerivativeB-double:A-int-double:A-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evalPartialDerivativeB</h4>
<pre>public&nbsp;double&nbsp;evalPartialDerivativeB(double[]&nbsp;weights,
                                     int&nbsp;index,
                                     double[]&nbsp;inputSignals,
                                     double&nbsp;true_lbl)</pre>
<div class="block">catch-all method for NNNodeIntf classes that do not implement this method.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>weights</code> - double[] all variables (including biases) array</dd>
<dd><code>index</code> - int the index of the partial derivative to take</dd>
<dd><code>inputSignals</code> - double[]</dd>
<dd><code>true_lbl</code> - double</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double</dd>
</dl>
</li>
</ul>
<a name="setLastDerivEvalCache-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLastDerivEvalCache</h4>
<pre>protected&nbsp;void&nbsp;setLastDerivEvalCache(double&nbsp;val)</pre>
<div class="block">cache last derivative evaluation.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>val</code> - double</dd>
</dl>
</li>
</ul>
<a name="getLastDerivEvalCache--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLastDerivEvalCache</h4>
<pre>protected&nbsp;double&nbsp;getLastDerivEvalCache()</pre>
<div class="block">get the last derivative evaluation.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double maybe NaN.</dd>
</dl>
</li>
</ul>
<a name="setLastEvalCache-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLastEvalCache</h4>
<pre>protected&nbsp;void&nbsp;setLastEvalCache(double&nbsp;val)</pre>
<div class="block">cache last evaluation.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>val</code> - double</dd>
</dl>
</li>
</ul>
<a name="getLastEvalCache--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLastEvalCache</h4>
<pre>public&nbsp;double&nbsp;getLastEvalCache()</pre>
<div class="block">get the last evaluation.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double maybe NaN.</dd>
</dl>
</li>
</ul>
<a name="setLastInputsCache-double:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLastInputsCache</h4>
<pre>protected&nbsp;void&nbsp;setLastInputsCache(double[]&nbsp;inputs)</pre>
<div class="block">cache last inputs.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>inputs</code> - double[]</dd>
</dl>
</li>
</ul>
<a name="getLastInputsCache--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLastInputsCache</h4>
<pre>public&nbsp;double[]&nbsp;getLastInputsCache()</pre>
<div class="block">get the last inputs.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double maybe NaN.</dd>
</dl>
</li>
</ul>
<a name="resetCache--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>resetCache</h4>
<pre>protected&nbsp;void&nbsp;resetCache()</pre>
<div class="block">reset the cache(s) of this node.</div>
</li>
</ul>
<a name="getGradVectorCache--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getGradVectorCache</h4>
<pre>protected&nbsp;double[]&nbsp;getGradVectorCache()</pre>
<div class="block">get the last grad vector. If it's null, a new array is created and stored
 in the cache (with NaN values) before being returned to the caller.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double[]</dd>
</dl>
</li>
</ul>
<a name="setGradVectorCache-double:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setGradVectorCache</h4>
<pre>protected&nbsp;void&nbsp;setGradVectorCache(double[]&nbsp;g)</pre>
<div class="block">update the last grad vector of this node.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>g</code> - double[]</dd>
</dl>
</li>
</ul>
<a name="setGradVectorCache-int-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setGradVectorCache</h4>
<pre>protected&nbsp;void&nbsp;setGradVectorCache(int&nbsp;i,
                                  double&nbsp;gi)</pre>
<div class="block">set the i-th coordinate of the last grad vector of this node.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>i</code> - int in {0,1,...#weights-1}</dd>
<dd><code>gi</code> - double the value of the ith component of this node's gradient</dd>
</dl>
</li>
</ul>
<a name="resetGradVectorCache--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>resetGradVectorCache</h4>
<pre>protected&nbsp;void&nbsp;resetGradVectorCache()</pre>
<div class="block">reset all components of the grad vector cache of this node to NaN values.</div>
</li>
</ul>
<a name="setLastDerivEvalCache2-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLastDerivEvalCache2</h4>
<pre>protected&nbsp;void&nbsp;setLastDerivEvalCache2(double&nbsp;val)</pre>
<div class="block">cache last derivative evaluation for use with the grad-vector caches.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>val</code> - double</dd>
</dl>
</li>
</ul>
<a name="getLastDerivEvalCache2--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLastDerivEvalCache2</h4>
<pre>protected&nbsp;double&nbsp;getLastDerivEvalCache2()</pre>
<div class="block">get the last derivative evaluation that is for use with grad-vector caches.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>double maybe NaN.</dd>
</dl>
</li>
</ul>
<a name="setDropout-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setDropout</h4>
<pre>public&nbsp;void&nbsp;setDropout(boolean&nbsp;val)</pre>
<div class="block">sets the dropout property of this node.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>val</code> - boolean</dd>
</dl>
</li>
</ul>
<a name="isDropout--">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>isDropout</h4>
<pre>public&nbsp;boolean&nbsp;isDropout()</pre>
<div class="block">gets the dropout property of this node.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>boolean</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="class-use/BaseNNNode.html">Use</a></li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../index-files/index-1.html">Index</a></li>
<li><a href="../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../popt4jlib/neural/Adam4FFNN.Adam4FFNNThread.html" title="class in popt4jlib.neural"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../popt4jlib/neural/CategoricalXEntropyLoss.html" title="class in popt4jlib.neural"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../index.html?popt4jlib/neural/BaseNNNode.html" target="_top">Frames</a></li>
<li><a href="BaseNNNode.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
