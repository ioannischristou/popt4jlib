dbglvl,2
# the following defines an ANN and weights on the nn's connections
# the ANN looks like this:
# INP L0    L1    OUT
# x1
# x2  N00   N10   
# x3  N01   N11   
# x4  ...   ...   y
# x5  ...   ...
# ... ...   N20
# ... N09
# x14
#class,outputlayer,popt4jlib.neural.CategoricalXEntropyLossW
class,outputlayer,popt4jlib.neural.MultiClassSSE
arrayofcopies,layer1_arr,10,popt4jlib.neural.Sigmoid,1.0
arrayofcopies,layer3_arr,11,popt4jlib.neural.Sigmoid,1.0
array,hiddenlayers,[Ljava.lang.Object;,layer1_arr,layer3_arr
# normalized train data:
matrix-1_1,ffnn.traindata,testdata/grid_data_ALLattrs_train_small.dat
# train labels
dblarray,ffnn.trainlabels,testdata/grid_data_ALLattrs_train_small.dat.lbls
#class,costfunc,popt4jlib.neural.costfunction.MSSE
class,costfunc,popt4jlib.neural.costfunction.MAE
# optimizer props
class,ffnn.mainoptimizer,popt4jlib.neural.SGD4FFNN
class,opt.function,popt4jlib.neural.FFNN4TrainB,hiddenlayers,outputlayer,costfunc,5
# opt.numthreads,4
# line below causes non-deterministic function evaluations, of small batches of
# input vectors, but runs a lot faster!
#ffnn.randombatchsize,2000
# rndgen,7,4
gradapproximator.nmax,8
sgd.a,0.99
sgd.decay_period,100
sgd.decay_factor,0.95
sgd.gtol,0.0
sgd.maxiters,5000
# new number of connection weights = 14*10 + 10*11 + 11 = 140 + 110 + 11 = 261
# new number of biases = 10 + 11 + 1 = 22
# number of dimensions = 283
sgd.numdimensions,283
# output file below used by [DGA,AVD]FFNNTest class
ffnn.outputlabelsfile,testdata/result_grid_data_ALLattrs_trainlabels_small.dat
