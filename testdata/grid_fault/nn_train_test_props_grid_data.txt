dbglvl,2
# the following defines an ANN and weights on the nn's connections
# the ANN looks like this:
# INP L0    L1    OUT
# x1
# x2  N01     
# x3  ...   N08   y  
# ... N07 
# x14    
class,n01,popt4jlib.neural.Sigmoid,1.0
class,n02,popt4jlib.neural.Sigmoid,1.0
class,n03,popt4jlib.neural.Sigmoid,1.0
class,n04,popt4jlib.neural.Sigmoid,1.0
class,n05,popt4jlib.neural.Sigmoid,1.0
class,n06,popt4jlib.neural.Sigmoid,1.0
class,n07,popt4jlib.neural.Sigmoid,1.0
class,outputlayer,popt4jlib.neural.Linear
array,layer1_arr,popt4jlib.neural.NNNodeIntf,n01,n02,n03,n04,n05,n06,n07
array,hiddenlayers,[Ljava.lang.Object;,layer1_arr
# train data
matrix,ffnn.traindata,testdata/grid_data_ALLattrs_train.dat
# train labels
dblarray,ffnn.trainlabels,testdata/grid_data_ALLattrs_train.dat.lbls
class,costfunc,popt4jlib.neural.costfunction.MAE
# weights to be tested
array,weights,double, 0.03520736744410427,-0.03578783974877298,3.858326138001888E-4,0.0030017068435773155,2.1095295488827532,2.3812320963147524,2.2851379652432753,0.02887914750829625,0.02924010620422999,0.09010868408951049,0.023468872182354942,2.055692735140756,2.4206236905038545,2.2343569115112807, 0.028187633369169535,  0.015060624527394956,0.023264360198857387,0.013532374691156132,0.01991354830134827,0.031030576308850352,-0.011508715044256025,0.04512919804880683,0.0012527215069111572,0.008969400542634023,-0.01776574576399921,0.03941485331339967,0.009615433314487262,-1.3497761844334655E-4,-0.012513894192045696, 0.010067605625884601,  -0.00329135406107145,0.008084723396192928,0.038289862062460475,-0.019473985032012045,0.03782071508311864,0.012525125867345277,-0.015171939345903475,0.01152682199390792,-0.047720467509583336,-0.04019177697054606,-0.014608288888265451,-0.018949945270677462,7.582281405445687E-4,0.04368746384891008, -0.013472537266408145,  0.03437349187277053,-0.022219868038949764,0.019573374266284735,0.018113349154760455,0.011010124284617527,-0.020714918281644915,0.04380279886485616,-0.012974768542347193,-0.037888061515981314,-0.014883198936083496,-0.044445027720715985,0.015174095656937808,0.020210166368001464,-0.039192150844137866, -0.023477390105132157,  -0.04228303248082698,-0.004609096437602177,0.0369138474987407,-0.0030215259474529743,-0.0048183649519376245,0.022215186704374695,-0.030918750812561582,0.01669289360263601,0.04053710118429624,0.038574617643929096,-0.033134232223493855,0.042712517722487214,0.03621472491769037,-0.0222394936465017, 0.04187897881641166,  -0.02772862797240819,-0.02600453145821633,0.02305788695135132,-0.028744007525466745,-0.02607503504107795,-0.018041053555312315,-0.016272425022951897,-0.016200380301221697,-0.010882355290349104,0.03914943662436988,0.04535601287417847,0.02776811201992571,-0.02230162429379153,-0.03169226005859692, 0.030430140345175452,  -0.028443133103507674,0.009370688452359348,0.007500201393019017,-0.029539547080495575,0.04436105164858076,0.014147171889112839,0.00656329776144767,0.004910732711111776,-0.02028755809602655,0.020092126214245894,-0.03284055121255532,-0.018214686200122055,0.007538108009380572,-0.002578303889522048, 0.03590713926727104,  1.6114231688972467,1.02209829668816,1.0575905366656162,1.0323505370530466,1.0558013028491633,0.9087796288042439,0.550030525368872, 1.0159773868729207
